{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03477f44-46c2-4a22-aaee-a67878c1816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  1 18:58:46 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8    30W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8    20W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e513c8-c521-4ac4-b93c-bea7dbb4eac9",
   "metadata": {},
   "source": [
    "##### %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de61d6ab-33e9-40ef-b448-6686a5a4e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# os.environ['http_proxy'] = \"http://127.0.0.1:3128\"\n",
    "# os.environ['https_proxy'] = \"http://127.0.0.1:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab062da-1f4d-4f54-965f-49e519bb897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a029d2ef-c060-410a-9c98-aa48d86c7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e1e8bc-99d9-4968-9956-fe13fc4433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bert_conv_custom import BertConfig, BertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26801a7a-b4e6-4faf-8da1-b8d953dd7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c443a-6995-43ca-ac1d-43cfe5ec376a",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef112d9-8b15-407a-b735-cc584072cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposeCustom(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransposeCustom, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.transpose(x, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411dce92-23fd-4258-ab4c-73b9f68f8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = BertConfig(is_decoder=True, \n",
    "#                     add_cross_attention=True,\n",
    "#                     ff_layer='conv',\n",
    "#                     conv_kernel=1,\n",
    "#                     conv_kernel_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711ae813-492d-4fe1-89ee-8315cb43617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_span_from_seeds(seeds, span, total=None):\n",
    "    inds = list()\n",
    "    for seed in seeds:\n",
    "        for i in range(seed, seed + span):\n",
    "            if total is not None and i >= total:\n",
    "                break\n",
    "            elif i not in inds:\n",
    "                inds.append(int(i))\n",
    "    return np.array(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d78b6b1-0a91-4706-92ca-f52a791ea753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_mask(shape, p, total, span, allow_no_inds=False):\n",
    "    # num_mask_spans = np.sum(np.random.rand(total) < p)\n",
    "    # num_mask_spans = int(p * total)\n",
    "    mask = torch.zeros(shape, requires_grad=False, dtype=torch.bool)\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        mask_seeds = list()\n",
    "        while not allow_no_inds and len(mask_seeds) == 0 and p > 0:\n",
    "            mask_seeds = np.nonzero(np.random.rand(total) < p)[0]\n",
    "\n",
    "        mask[i, _make_span_from_seeds(mask_seeds, span, total=total)] = True\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e79430c-e70e-4e42-8f35-3bbae19c2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        position = (position.T - position).T / max_len\n",
    "        self.register_buffer('rel_position', position)\n",
    "        \n",
    "        self.conv = torch.nn.Conv1d(max_len, d_model, 25, padding=25 // 2, groups=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        rel_pos = self.conv(self.rel_position[:x.size(1), :x.size(1)][None])[0].T\n",
    "        print(rel_pos.shape)\n",
    "        x = x + rel_pos\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ade54a7-ca7a-48c7-bb53-85a0f741d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGEmbedder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGEmbedder, self).__init__()\n",
    "        config = BertConfig(is_decoder=False, \n",
    "                    add_cross_attention=False,\n",
    "                    ff_layer='linear',\n",
    "                    hidden_size=512,\n",
    "                    num_attention_heads=8,\n",
    "                    num_hidden_layers=8,\n",
    "                    conv_kernel=1,\n",
    "                    conv_kernel_num=1)\n",
    "        self.model = BertEncoder(config)\n",
    "        \n",
    "        self.pos_e = PositionalEncoding(512, max_len=6000)\n",
    "        self.ch_embedder = torch.nn.Embedding(len(mitsar_chls), 512)\n",
    "        self.ch_norm = torch.nn.LayerNorm(512)\n",
    "        \n",
    "        self.input_norm = torch.nn.LayerNorm(2)\n",
    "        self.input_embedder = torch.nn.Sequential(\n",
    "            TransposeCustom(),\n",
    "            torch.nn.Conv1d(2, 32, 5, 2, padding=0),\n",
    "            torch.nn.Conv1d(32, 64, 5, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(64 // 2, 64),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(64, 128, 3, 2, padding=0),\n",
    "            torch.nn.Conv1d(128, 196, 3, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(196 // 2, 196),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(196, 256, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(256, 384, 5, 1, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(384 // 2, 384),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(384, 512, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(512, 512, 1, 1, padding=0),\n",
    "            torch.nn.GroupNorm(512 // 2, 512),\n",
    "            torch.nn.GELU(),\n",
    "            TransposeCustom(),\n",
    "        # torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        # self.input_norm = torch.nn.LayerNorm(10)\n",
    "        # self.output_embedder = torch.nn.Conv1d(512, 512, 1)\n",
    "        self.output_embedder = torch.nn.Linear(512, 512)\n",
    "        self.transpose = TransposeCustom()\n",
    "        \n",
    "        self.mask_embedding = torch.nn.Parameter(torch.normal(0, 512**(-0.5), size=(512,)),\n",
    "                                                   requires_grad=True)\n",
    "        \n",
    "    def single_forward(self, inputs, attention_mask, ch_vector, placeholder):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        # print(embedding.shape, ch_embedding.shape)\n",
    "        embedding += ch_embedding\n",
    "        # embedding = self.ch_norm(embedding)\n",
    "        # we lost some channel specific information\n",
    "        embedding_unmasked = embedding.clone()\n",
    "        \n",
    "        mask = _make_mask((embedding.shape[0], embedding.shape[1]), 0.05, embedding.shape[1], 10)\n",
    "        embedding[mask] = self.mask_embedding\n",
    "        \n",
    "        # for b_i in range(embedding.shape[0]):\n",
    "        #     embedding_masked[b_i][mask[b_i]] = self.mask_embedding\n",
    "        \n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "        encoder_output = self.output_embedder(encoder_output)\n",
    "        # encoder_output = self.transpose(encoder_output)\n",
    "        return encoder_output[:, 1:], embedding_unmasked\n",
    "    \n",
    "    def forward(self, a, mask, ch_vector, placeholder):\n",
    "        a_downsampled_embedding, label = self.single_forward(a, mask, ch_vector, placeholder)\n",
    "        \n",
    "        return a_downsampled_embedding, label\n",
    "    \n",
    "    def infer(self, a, ch_vector, placeholder):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        # print(embedding.shape, ch_embedding.shape)\n",
    "        embedding += ch_embedding\n",
    "        # embedding = self.ch_norm(embedding)\n",
    "            \n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "        \n",
    "        encoder_output = self.output_embedder(self.transpose(encoder_output))\n",
    "        return encoder_output, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77774c12-ce6f-47f6-87fe-9b158fdcfdee",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d6c08d-49a6-4789-a24f-929cb2bd294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_negatives(z):\n",
    "    \"\"\"Generate negative samples to compare each sequence location against\"\"\"\n",
    "    num_negatives = 20\n",
    "    batch_size, feat, full_len = z.shape\n",
    "    z_k = z.permute([0, 2, 1]).reshape(-1, feat)\n",
    "    with torch.no_grad():\n",
    "        # candidates = torch.arange(full_len).unsqueeze(-1).expand(-1, self.num_negatives).flatten()\n",
    "        negative_inds = torch.randint(0, full_len-1, size=(batch_size, full_len * num_negatives))\n",
    "        # From wav2vec 2.0 implementation, I don't understand\n",
    "        # negative_inds[negative_inds >= candidates] += 1\n",
    "\n",
    "        for i in range(1, batch_size):\n",
    "            negative_inds[i] += i * full_len\n",
    "\n",
    "    z_k = z_k[negative_inds.view(-1)].view(batch_size, full_len, num_negatives, feat)\n",
    "    return z_k, negative_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534e0a28-d364-424b-95ea-ba9aef8969e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_similarity( z, c, negatives):\n",
    "    c = c[..., :].permute([0, 2, 1]).unsqueeze(-2)\n",
    "    z = z.permute([0, 2, 1]).unsqueeze(-2)\n",
    "\n",
    "    # In case the contextualizer matches exactly, need to avoid divide by zero errors\n",
    "    negative_in_target = (c == negatives).all(-1)\n",
    "    targets = torch.cat([c, negatives], dim=-2)\n",
    "\n",
    "    logits = torch.nn.functional.cosine_similarity(z, targets, dim=-1) / 0.1\n",
    "    if negative_in_target.any():\n",
    "        logits[1:][negative_in_target] = float(\"-inf\")\n",
    "\n",
    "    return logits.view(-1, logits.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9679b5-eb5e-45e8-a042-88c24489b697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39fbf98e-eee4-4232-b16d-33c35d176f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(ts):\n",
    "    start_shift = np.random.choice(range(10))\n",
    "    downsampling = 2\n",
    "    indices = np.random.choice(np.array(list(range(110)))[start_shift::10][::downsampling], 5, replace=False)\n",
    "    masked_idx = []\n",
    "    for i in indices:\n",
    "        masked_idx.extend(range(i, i+10))\n",
    "\n",
    "    masked_idx = np.array(masked_idx)\n",
    "    \n",
    "    # mask = np.ones((6000, 2))\n",
    "    # # desync some masked channels\n",
    "    # ts_masked = ts.copy()\n",
    "    # if np.random.choice([0, 1], p=[0.7, 0.3]):\n",
    "    #     ts_masked[masked_idx, np.random.choice([0, 1])] *= 0\n",
    "    # else:\n",
    "    #     ts_masked[masked_idx] *= 0\n",
    "        \n",
    "    return None, masked_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368cce54-d9fc-4d65-9341-34b1fadebe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({0: tensor(2.4250), 1: tensor(1.9767)},\n",
    "#  {0: tensor(66.8642), 1: tensor(46.8854)})\n",
    "\n",
    "mean_dict = {0: (0.9631),\n",
    " 1: (1.0248),\n",
    " 2: (1.3041),\n",
    " 3: (0.),\n",
    " 4: (1.5822),\n",
    " 5: (1.7250),\n",
    " 6: (0.9935),\n",
    " 7: (0.9548),\n",
    " 8: (0.7488),\n",
    " 9: (1.3948),\n",
    " 10: (0.8879),\n",
    " 11: (1.0527),\n",
    " 12: (1.3401),\n",
    " 13: (1.5541),\n",
    " 14: (1.2600),\n",
    " 15: (1.0487),\n",
    " 16: (0.7529),\n",
    " 17: (1.6566),\n",
    " 18: (0.9272),\n",
    " 19: (1.2238),\n",
    " 20: (1.2619),\n",
    " 21: (1.5236)}\n",
    "\n",
    "std_dict = {0: (64.1294),\n",
    " 1: (64.1984),\n",
    " 2: (45.9215),\n",
    " 3: (0.),\n",
    " 4: (45.1312),\n",
    " 5: (51.7621),\n",
    " 6: (43.5150),\n",
    " 7: (39.7182),\n",
    " 8: (46.8787),\n",
    " 9: (49.0797),\n",
    " 10: (52.2342),\n",
    " 11: (51.9236),\n",
    " 12: (50.7353),\n",
    " 13: (52.1277),\n",
    " 14: (48.8627),\n",
    " 15: (42.7040),\n",
    " 16: (46.5815),\n",
    " 17: (60.2403),\n",
    " 18: (41.6082),\n",
    " 19: (44.6035),\n",
    " 20: (82.8107),\n",
    " 21: (53.5717)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "403a5a1e-54dc-4134-b747-13da890c0c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 18:58:50.882690: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "003c6229-82b7-4dc3-9d01-5539f3ca1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEST(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        super(TEST, self).__init__()\n",
    "        self.main_path = path\n",
    "        self.paths = path\n",
    "        # self.paths = ['{}/{}'.format(self.main_path, i) for i in os.listdir(self.main_path)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        # take 60s of recording with specified shift\n",
    "        key = False\n",
    "        while(key == False):\n",
    "            try:\n",
    "                sample = np.load(path, allow_pickle=True).item()['value']\n",
    "                key = True\n",
    "            except Exception as e:\n",
    "                print(\"Path: {} is broken \".format(path), e)\n",
    "                path = np.random.choice(self.paths, 1)[0]\n",
    "                # sample = np.load(path, allow_pickle=True).item()['value']\n",
    "        real_len = sample.shape[0]\n",
    "        # if np.random.choice([0, 1], p=[0.9, 0.1]):\n",
    "        #     real_len = np.random.randint(real_len // 2, real_len)\n",
    "            \n",
    "        sample = sample[:real_len]\n",
    "        # sample = torch.from_numpy(sample[:6000].astype(np.float32)).clone()\n",
    "        channels_ids = [i for i, val in enumerate(mitsar_chls) if i != 3]\n",
    "        \n",
    "        # choose 2 random channels\n",
    "        channels_to_train = np.random.choice(channels_ids, 2, replace=False)\n",
    "        channels_vector = torch.tensor((channels_to_train))\n",
    "        sample = sample[:, channels_to_train]\n",
    "        \n",
    "        sample_norm = (sample - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector]) / (tuh_filtered_stat_vals['max_vals_filtered'][channels_vector] - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector] + 1e-6)\n",
    "        # sample_norm = sample_norm * 2 - 1\n",
    "        # _, mask = masking(sample_norm)\n",
    "        \n",
    "        if sample_norm.shape[0] < 6000:\n",
    "            sample_norm = np.pad(sample_norm, ((0, 6000 - sample_norm.shape[0]), (0, 0)))\n",
    "        \n",
    "        attention_mask = torch.ones(6000)\n",
    "        attention_mask[real_len:] = 0\n",
    "        return {'anchor': torch.from_numpy(sample_norm).float(), \n",
    "                # 'label': sample_label, \n",
    "                # 'anchor_masked': torch.from_numpy(sample_masked).float(), \n",
    "                # 'mask': torch.tensor(mask),\n",
    "                'channels': channels_vector,\n",
    "                'attention_mask': attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b550f5d0-1e1b-4371-afd5-979b388e48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuh_filtered_stat_vals = np.load('/home/data/TUH_pretrain.filtered_1_40/stat_vals.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af36d24f-b04f-4313-8834-3656d77b6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths = []\n",
    "# for path1 in os.listdir('/home/data/TUH_pretrain.filtered_1_40/'):\n",
    "#     if 'npy' not in path1:\n",
    "#         for path2 in os.listdir('/home/data/TUH_pretrain.filtered_1_40/{}'.format(path1)):\n",
    "#             for path3 in os.listdir('/home/data/TUH_pretrain.filtered_1_40//{}/{}'.format(path1, path2)):\n",
    "#                 file_paths.append('/home/data/TUH_pretrain.filtered_1_40//{}/{}/{}'.format(path1, path2, path3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e492473f-c1f5-431d-8717-f10686e94ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03b28335-daea-4b30-8c4b-db2237fea88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = {}\n",
    "\n",
    "# for path in file_paths:\n",
    "#     tmp[path] = np.load(path, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790c40b-6ae4-47da-8819-9cf8c4963a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa37800-b698-4e3c-92aa-80b53636eed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6f27d69-039e-45dc-b62e-32746891d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes = np.load('/home/data/TUH_pretrain.filtered_1_40/sizes.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e4b7bff-c620-4117-a9e9-9467a4486809",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_paths = [i for i in file_paths if sizes[i][0] > 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eedaeca9-8ec9-4e52-b51a-3ad3a41eb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitted_paths = []\n",
    "# for path in file_paths:\n",
    "#     shape = sizes[path][0]\n",
    "#     for i in range(0, shape, 6000):\n",
    "#         if (shape - i > 6000):\n",
    "#             splitted_paths.append((path, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9402e789-65af-4b04-a351-620f227531b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_paths = ['/home/data/TUH_pretrain.filtered_1_40.splited/{}'.format(i) for i in os.listdir('/home/data/TUH_pretrain.filtered_1_40.splited/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9ad2e2d-c13c-4edd-9c7a-f214938b8ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/data/TUH_pretrain.filtered_1_40.splited/2585_264000.npy'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(splitted_paths, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "354bc4ee-ee88-402e-bea8-881e40f16314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365495"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a413d97-8fc1-47a6-b137-3ac8247cf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitsar_chls = ['Fp1', 'Fp2', 'FZ', 'FCz', 'Cz', 'Pz', 'O1', 'O2', 'F3', 'F4', \n",
    "               'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n",
    "mitsar_chls = [i.upper() for i in mitsar_chls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da834726-54e3-47a5-aee5-5559f2db6274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TEST(splitted_paths)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a48eb7-0727-43ea-bedb-cd419ecd6532",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95ba1c89-cf1d-48d6-a6dd-4f8b0432ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c49688-e680-406f-9de5-2eae316eeb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50e2bc04-d8ab-4095-8081-c6e8d56fd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class NoamLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, d_model=512):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d_model = d_model\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = max(1, self.last_epoch)\n",
    "        factor = min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # scale = self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # return [base_lr * scale for base_lr in self.base_lrs]\n",
    "        return [base_lr * self.d_model ** (-0.5) * factor for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cd39442-574d-489d-9cae-2886fa7b2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "def cosloss(anchor, real, negative):\n",
    "    a = torch.exp(cossim(anchor, real)) / 0.1\n",
    "    b = sum([torch.exp(cossim(anchor, negative[:, n])) / 0.1 for n in range(negative.shape[1])]) + 1e-6\n",
    "    return -torch.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e28e456c-e80d-4cf6-ad0b-4c6af1427908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    random.seed(torch_seed + worker_id)\n",
    "    np.random.seed((torch_seed + worker_id) % 2**30)\n",
    "\n",
    "train_dataset = TEST(splitted_paths[:-15000])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "test_dataset = TEST(splitted_paths[-15000:])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bc0dce6-c149-4043-bf79-d84a337177fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "lr_d = 1\n",
    "acc_size = 1\n",
    "training_epochs1 = 150000 // len(train_loader)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr_d)\n",
    "\n",
    "model_test = torch.nn.DataParallel(model)\n",
    "model_test.to('cuda:0')\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optim, start_factor=1.0, end_factor=0.1, total_iters=training_epochs1*len(train_loader))\n",
    "scheduler = NoamLR(optim, 100000, 512)\n",
    "\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25684f3b-1b46-41f3-ab64-342dd82ffb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5476, 27, 147852)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), training_epochs1, training_epochs1 * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a8ee36c-93ab-408d-9171-951b2d01c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()(batch['anchor'][None], batch['mask'][None], batch['channels'][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301d68b-775a-47a1-a1a9-ff2ff4d20b3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train\t1.1030877828598022\n",
      "Loss/train\t1.1205166578292847\n",
      "Loss/train\t1.172516942024231\n",
      "Loss/train\t1.148479700088501\n",
      "Loss/train\t1.1080737113952637\n",
      "Loss/train\t1.1164870262145996\n",
      "Loss/train\t1.1132405996322632\n",
      "Loss: 1.1013708114624023\t\n",
      "Loss/train\t1.0995947122573853\n",
      "Loss/train\t1.1270442008972168\n",
      "Loss/train\t1.0850714445114136\n",
      "Loss/train\t1.0480189323425293\n",
      "Loss/train\t1.038840413093567\n",
      "Loss/train\t1.047231674194336\n",
      "Loss/train\t1.0649646520614624\n",
      "Loss/train\t1.0510094165802002\n",
      "Loss/train\t1.071996808052063\n",
      "Loss/train\t1.0528682470321655\n",
      "Loss: 1.0501459836959839\t\n",
      "Loss/train\t1.0457582473754883\n",
      "Loss/train\t1.0784471035003662\n",
      "Loss/train\t0.9939504861831665\n",
      "Loss/train\t1.0439149141311646\n",
      "Loss/train\t0.9971293210983276\n",
      "Loss/train\t1.04259192943573\n",
      "Loss/train\t1.0033913850784302\n",
      "Loss/train\t1.0128108263015747\n",
      "Loss/train\t1.0224108695983887\n",
      "Loss/train\t1.02928626537323\n",
      "Loss: 1.0030395984649658\t\n",
      "Loss/train\t1.0195443630218506\n",
      "Loss/train\t1.0206608772277832\n",
      "Loss/train\t0.9925925135612488\n",
      "Loss/train\t0.9921804666519165\n",
      "Loss/train\t0.9583582878112793\n",
      "Loss/train\t0.9839385747909546\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.9851022362709045\n",
      "Loss/train\t0.9372044205665588\n",
      "Loss/train\t1.031301498413086\n",
      "Loss/train\t0.9535825848579407\n",
      "Loss: 0.9647108316421509\t\n",
      "Loss/train\t1.0121290683746338\n",
      "Loss/train\t0.9372467398643494\n",
      "Loss/train\t0.9514421820640564\n",
      "Loss/train\t0.9412779808044434\n",
      "Loss/train\t0.9181632399559021\n",
      "Loss/train\t0.9107558131217957\n",
      "Loss/train\t0.9139245748519897\n",
      "Loss/train\t0.9451804757118225\n",
      "Loss/train\t0.9290397763252258\n",
      "Loss/train\t0.9171234369277954\n",
      "Loss: 0.9152229428291321\t\n",
      "Loss/train\t0.8796103000640869\n",
      "Loss/train\t0.8957765102386475\n",
      "Loss/train\t0.9229657649993896\n",
      "Loss/train\t0.8792769312858582\n",
      "Loss/train\t0.8848893046379089\n",
      "Loss/train\t0.8850984573364258\n",
      "Loss/train\t0.8901118040084839\n",
      "Loss/train\t0.9094049334526062\n",
      "Loss/train\t0.8921449780464172\n",
      "Loss/train\t0.8588796257972717\n",
      "Loss: 0.8768771886825562\t\n",
      "Loss/train\t0.8864716291427612\n",
      "Loss/train\t0.8635668754577637\n",
      "Loss/train\t0.8761666417121887\n",
      "Loss/train\t0.8646314144134521\n",
      "Loss/train\t0.8407676815986633\n",
      "Loss/train\t0.8302415609359741\n",
      "Loss/train\t0.8356423377990723\n",
      "Loss/train\t0.8943421840667725\n",
      "Loss/train\t0.8564330339431763\n",
      "Loss/train\t0.8422819972038269\n",
      "Loss: 0.8367028832435608\t\n",
      "Loss/train\t0.8327392339706421\n",
      "Loss/train\t0.8257465362548828\n",
      "Loss/train\t0.8416097164154053\n",
      "Loss/train\t0.8049086928367615\n",
      "Loss/train\t0.8164917826652527\n",
      "Loss/train\t0.8008993864059448\n",
      "Loss/train\t0.8021548986434937\n",
      "Loss/train\t0.8078641891479492\n",
      "Loss/train\t0.7815791368484497\n",
      "Loss/train\t0.8322293162345886\n",
      "Loss: 0.8171612620353699\t\n",
      "Loss/train\t0.8224613666534424\n",
      "Loss/train\t0.8759992122650146\n",
      "Loss/train\t0.8252213001251221\n",
      "Loss/train\t0.7810137271881104\n",
      "Loss/train\t0.8078402876853943\n",
      "Loss/train\t0.8463601469993591\n",
      "Loss/train\t0.7836030721664429\n",
      "Loss/train\t0.7738261222839355\n",
      "Loss/train\t0.786020040512085\n",
      "Loss/train\t0.786961555480957\n",
      "Loss: 0.7792032957077026\t\n",
      "Loss/train\t0.758607029914856\n",
      "Loss/train\t0.7585479617118835\n",
      "Loss/train\t0.7650398015975952\n",
      "Loss/train\t0.7434312701225281\n",
      "Loss/train\t0.7516027688980103\n",
      "Loss/train\t0.7852097749710083\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.769671618938446\n",
      "Loss/train\t0.749401867389679\n",
      "Loss/train\t0.7689647078514099\n",
      "Loss/train\t0.7558296322822571\n",
      "Loss: 0.7501322627067566\t\n",
      "Loss/train\t0.7150960564613342\n",
      "Loss/train\t0.7804796695709229\n",
      "Loss/train\t0.7681908011436462\n",
      "Loss/train\t0.7519882917404175\n",
      "Loss/train\t0.7503471374511719\n",
      "Loss/train\t0.6980521082878113\n",
      "Loss/train\t0.7186662554740906\n",
      "Loss/train\t0.7390150427818298\n",
      "Loss/train\t0.7320569753646851\n",
      "Loss/train\t0.7245497703552246\n",
      "Loss: 0.7136753797531128\t\n",
      "Loss/train\t0.7315611839294434\n",
      "Loss/train\t0.733356237411499\n",
      "Loss/train\t0.7270450592041016\n",
      "Loss/train\t0.6941317319869995\n",
      "Loss/train\t0.7010098695755005\n",
      "Loss/train\t0.7081705927848816\n",
      "Loss/train\t0.7220122218132019\n",
      "Loss/train\t0.699019193649292\n",
      "Loss/train\t0.6824468374252319\n",
      "Loss/train\t0.7546480298042297\n",
      "Loss: 0.764164388179779\t\n",
      "Loss/train\t0.7335258722305298\n",
      "Loss/train\t0.6976220607757568\n",
      "Loss/train\t0.6836299300193787\n",
      "Loss/train\t0.7045724987983704\n",
      "Loss/train\t0.6640474796295166\n",
      "Loss/train\t0.7118374705314636\n",
      "Loss/train\t0.7037408947944641\n",
      "Loss/train\t0.6909347772598267\n",
      "Loss/train\t0.6502972841262817\n",
      "Loss/train\t0.6873090863227844\n",
      "Loss: 0.6746658086776733\t\n",
      "Loss/train\t0.6690295338630676\n",
      "Loss/train\t0.6683547496795654\n",
      "Loss/train\t0.6755749583244324\n",
      "Loss/train\t0.6447209119796753\n",
      "Loss/train\t0.6714038848876953\n",
      "Loss/train\t0.6602778434753418\n",
      "Loss/train\t0.6678752899169922\n",
      "Loss/train\t0.6708772778511047\n",
      "Loss/train\t0.6982789039611816\n",
      "Loss/train\t0.6773924231529236\n",
      "Loss: 0.6733396649360657\t\n",
      "Loss/train\t0.6703971028327942\n",
      "Loss/train\t0.6699832081794739\n",
      "Loss/train\t0.6340557932853699\n",
      "Loss/train\t0.6393792033195496\n",
      "Loss/train\t0.6434651613235474\n",
      "Loss/train\t0.6469152569770813\n",
      "Loss/train\t0.6189603209495544\n",
      "Loss/train\t0.6529386043548584\n",
      "Loss/train\t0.6307756304740906\n",
      "Loss/train\t0.6420300006866455\n",
      "Loss: 0.6414554119110107\t\n",
      "Loss/train\t0.6173103451728821\n",
      "Loss/train\t0.6557143926620483\n",
      "Loss/train\t0.6310166120529175\n",
      "Loss/train\t0.6279855370521545\n",
      "Loss/train\t0.6531820893287659\n",
      "Loss/train\t0.6156426072120667\n",
      "Loss/train\t0.624972403049469\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.6392030715942383\n",
      "Loss/train\t0.62826007604599\n",
      "Loss/train\t0.6839755773544312\n",
      "Loss: 0.6669344305992126\t\n",
      "Loss/train\t0.6264535784721375\n",
      "Loss/train\t0.6517489552497864\n",
      "Loss/train\t0.6164655685424805\n",
      "Loss/train\t0.66457599401474\n",
      "Loss/train\t0.6207001209259033\n",
      "Loss/train\t0.6581326127052307\n",
      "Loss/train\t0.6114256381988525\n",
      "Loss/train\t0.602673351764679\n",
      "Loss/train\t0.6189755797386169\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.6311432123184204\n",
      "Loss: 0.6096447706222534\t\n",
      "Loss/train\t0.5917907357215881\n",
      "Loss/train\t0.5979729890823364\n",
      "Loss/train\t0.5785108804702759\n",
      "Loss/train\t0.6638032793998718\n",
      "Loss/train\t0.6164150834083557\n",
      "Loss/train\t0.6420038342475891\n",
      "Loss/train\t0.5977800488471985\n",
      "Loss/train\t0.6064490079879761\n",
      "Loss/train\t0.6219481825828552\n",
      "Loss/train\t0.6282604336738586\n",
      "Loss: 0.6176283955574036\t\n",
      "Loss/train\t0.6425175070762634\n",
      "Loss/train\t0.6121705770492554\n",
      "Loss/train\t0.6179338693618774\n",
      "Loss/train\t0.6545373201370239\n",
      "Loss/train\t0.6123679876327515\n",
      "Loss/train\t0.6318944692611694\n",
      "Loss/train\t0.5893794894218445\n",
      "Loss/train\t0.6305850744247437\n",
      "Loss/train\t0.5911820530891418\n",
      "Loss/train\t0.5947019457817078\n",
      "Loss: 0.6054731607437134\t\n",
      "Loss/train\t0.6399194598197937\n",
      "Loss/train\t0.5644940733909607\n",
      "Loss/train\t0.5918768644332886\n",
      "Loss/train\t0.5875332951545715\n",
      "Loss/train\t0.5845687985420227\n",
      "Loss/train\t0.6044180393218994\n",
      "Loss/train\t0.6291404962539673\n",
      "Loss/train\t0.5801188349723816\n",
      "Loss/train\t0.6217901110649109\n",
      "Loss/train\t0.5876390933990479\n",
      "Loss: 0.5841615200042725\t\n",
      "Loss/train\t0.5918234586715698\n",
      "Loss/train\t0.5647250413894653\n",
      "Loss/train\t0.5891996026039124\n",
      "Loss/train\t0.5856849551200867\n",
      "Loss/train\t0.59612637758255\n",
      "Loss/train\t0.5750216841697693\n",
      "Loss/train\t0.596762478351593\n",
      "Loss/train\t0.6033849716186523\n",
      "Loss/train\t0.6082417964935303\n",
      "Loss/train\t0.5642663836479187\n",
      "Loss: 0.5834877490997314\t\n",
      "Loss/train\t0.5867489576339722\n",
      "Loss/train\t0.602398157119751\n",
      "Loss/train\t0.5799598693847656\n",
      "Loss/train\t0.5769733786582947\n",
      "Loss/train\t0.5850685834884644\n",
      "Loss/train\t0.5623741149902344\n",
      "Loss/train\t0.5469669103622437\n",
      "Loss/train\t0.566294252872467\n",
      "Loss/train\t0.5830070972442627\n",
      "Loss/train\t0.5763500928878784\n",
      "Loss: 0.5738101601600647\t\n",
      "Loss/train\t0.6086339950561523\n",
      "Loss/train\t0.5860841870307922\n",
      "Loss/train\t0.5626019239425659\n",
      "Loss/train\t0.5780326724052429\n",
      "Loss/train\t0.5488775968551636\n",
      "Loss/train\t0.567046046257019\n",
      "Loss/train\t0.5444886088371277\n",
      "Loss/train\t0.5682559609413147\n",
      "Loss/train\t0.603046715259552\n",
      "Loss/train\t0.5786483883857727\n",
      "Loss: 0.5811915397644043\t\n",
      "Loss/train\t0.5699212551116943\n",
      "Loss/train\t0.6050911545753479\n",
      "Loss/train\t0.5663139224052429\n",
      "Loss/train\t0.5576881766319275\n",
      "Loss/train\t0.5651208162307739\n",
      "Loss/train\t0.6906043291091919\n",
      "Loss/train\t0.6553187370300293\n",
      "Loss/train\t0.5741780996322632\n",
      "Loss/train\t0.5791612267494202\n",
      "Loss/train\t0.5592532157897949\n",
      "Loss: 0.5700098276138306\t\n",
      "Loss/train\t0.5995019674301147\n",
      "Loss/train\t0.5702192187309265\n",
      "Loss/train\t0.5733873248100281\n",
      "Loss/train\t0.5865612626075745\n",
      "Loss/train\t0.5689114332199097\n",
      "Loss/train\t0.5849670767784119\n",
      "Loss/train\t0.5812849402427673\n",
      "Loss/train\t0.5724417567253113\n",
      "Loss/train\t0.5483717322349548\n",
      "Loss/train\t0.5439705848693848\n",
      "Loss: 0.5621774792671204\t\n",
      "Loss/train\t0.5847296118736267\n",
      "Loss/train\t0.581428587436676\n",
      "Loss/train\t0.5920853614807129\n",
      "Loss/train\t0.5487878918647766\n",
      "Loss/train\t0.5626478791236877\n",
      "Loss/train\t0.5586448311805725\n",
      "Loss/train\t0.5715726017951965\n",
      "Loss/train\t0.5573095679283142\n",
      "Loss/train\t0.5675898790359497\n",
      "Loss/train\t0.5731390714645386\n",
      "Loss: 0.5629406571388245\t\n",
      "Loss/train\t0.5406018495559692\n",
      "Loss/train\t0.5843300223350525\n",
      "Loss/train\t0.5526959896087646\n",
      "Loss/train\t0.5808728337287903\n",
      "Loss/train\t0.5632860660552979\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.550535261631012\n",
      "Loss/train\t0.5420213341712952\n",
      "Loss/train\t0.5689131021499634\n",
      "Loss/train\t0.5361459255218506\n",
      "Loss/train\t0.5618614554405212\n",
      "Loss: 0.5580893158912659\t\n",
      "Loss/train\t0.5605847239494324\n",
      "Loss/train\t0.5556910634040833\n",
      "Loss/train\t0.525574803352356\n",
      "Loss/train\t0.5588845014572144\n",
      "Loss/train\t0.5534991025924683\n",
      "Loss/train\t0.5432072877883911\n",
      "Loss/train\t0.5399388074874878\n",
      "Loss/train\t0.5615162253379822\n",
      "Loss/train\t0.5707273483276367\n",
      "Loss/train\t0.5588984489440918\n",
      "Loss: 0.562731921672821\t\n",
      "Loss/train\t0.543819010257721\n",
      "Loss/train\t0.5734099745750427\n",
      "Loss/train\t0.5575492978096008\n",
      "Loss/train\t0.5460415482521057\n",
      "Loss/train\t0.5473909378051758\n",
      "Loss/train\t0.5640206933021545\n",
      "Loss/train\t0.5450748205184937\n",
      "Loss/train\t0.5382751822471619\n",
      "Loss/train\t0.531862735748291\n",
      "Loss/train\t0.5460820198059082\n",
      "Loss: 0.5450358986854553\t\n",
      "Loss/train\t0.5446200966835022\n",
      "Loss/train\t0.5490671992301941\n",
      "Loss/train\t0.5517606139183044\n",
      "Loss/train\t0.5377469062805176\n",
      "Loss/train\t0.5768555402755737\n",
      "Loss/train\t0.5541478991508484\n",
      "Loss/train\t0.5413542985916138\n",
      "Loss/train\t0.5510379076004028\n",
      "Loss/train\t0.5392117500305176\n",
      "Loss/train\t0.5380029678344727\n",
      "Loss: 0.5436657071113586\t\n",
      "Loss/train\t0.5502836108207703\n",
      "Loss/train\t0.5559471249580383\n",
      "Loss/train\t0.548122763633728\n",
      "Loss/train\t0.5328636169433594\n",
      "Loss/train\t0.5384297370910645\n",
      "Loss/train\t0.5228456258773804\n",
      "Loss/train\t0.5501973032951355\n",
      "Loss/train\t0.5214482545852661\n",
      "Loss/train\t0.5587603449821472\n",
      "Loss/train\t0.5792974233627319\n",
      "Loss: 0.5575116276741028\t\n",
      "Loss/train\t0.5483061075210571\n",
      "Loss/train\t0.5365495681762695\n",
      "Loss/train\t0.5563619136810303\n",
      "Loss/train\t0.5507187247276306\n",
      "Loss/train\t0.5340465307235718\n",
      "Loss/train\t0.5552067756652832\n",
      "Loss/train\t0.5354259014129639\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.5415706038475037\n",
      "Loss/train\t0.5382573008537292\n",
      "Loss/train\t0.5341289043426514\n",
      "Loss: 0.5417546033859253\t\n",
      "Loss/train\t0.5455688834190369\n",
      "Loss/train\t0.5612719058990479\n",
      "Loss/train\t0.5469149351119995\n",
      "Loss/train\t0.5345447063446045\n",
      "Loss/train\t0.5377980470657349\n",
      "Loss/train\t0.5247373580932617\n",
      "Loss/train\t0.5355328321456909\n",
      "Loss/train\t0.5318039655685425\n",
      "Loss/train\t0.542817234992981\n",
      "Loss/train\t0.554634153842926\n",
      "Loss: 0.5553292036056519\t\n",
      "Loss/train\t0.5466139316558838\n",
      "Loss/train\t0.5452732443809509\n",
      "Loss/train\t0.5448806881904602\n",
      "Loss/train\t0.5275668501853943\n",
      "Loss/train\t0.5451577305793762\n",
      "Loss/train\t0.5414686799049377\n",
      "Loss/train\t0.5542071461677551\n",
      "Loss/train\t0.550991415977478\n",
      "Loss/train\t0.5220023393630981\n",
      "Loss/train\t0.5486940741539001\n",
      "Loss: 0.5491169691085815\t\n",
      "Loss/train\t0.5508344769477844\n",
      "Loss/train\t0.513454794883728\n",
      "Loss/train\t0.5235303640365601\n",
      "Loss/train\t0.5503608584403992\n",
      "Loss/train\t0.540176272392273\n",
      "Loss/train\t0.5549700856208801\n",
      "Loss/train\t0.5336527824401855\n",
      "Loss/train\t0.5350047945976257\n",
      "Loss/train\t0.5548474788665771\n",
      "Loss/train\t0.5247723460197449\n",
      "Loss: 0.5411047339439392\t\n",
      "Loss/train\t0.5287489891052246\n",
      "Loss/train\t0.5215948224067688\n",
      "Loss/train\t0.5257149934768677\n",
      "Loss/train\t0.5366774201393127\n",
      "Loss/train\t0.6045202016830444\n",
      "Loss/train\t0.5287615060806274\n",
      "Loss/train\t0.5262570977210999\n",
      "Loss/train\t0.541530191898346\n",
      "Loss/train\t0.5272852778434753\n",
      "Loss/train\t0.5493456125259399\n",
      "Loss: 0.5452466607093811\t\n",
      "Loss/train\t0.5478649139404297\n",
      "Path: /home/data/TUH_pretrain.filtered_1_40.splited/217.npy is broken  Failed to interpret file '/home/data/TUH_pretrain.filtered_1_40.splited/217.npy' as a pickle\n",
      "Loss/train\t0.5552728176116943\n",
      "Loss/train\t0.5472425818443298\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(training_epochs1):\n",
    "    mean_loss = 0\n",
    "    acc_step = 0\n",
    "    for batch in train_loader:\n",
    "        # batch = train_dataset.__getitem__(i)\n",
    "        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "        ae, label = model_test(\n",
    "            batch['anchor'],#.to('cuda:0'), \n",
    "            None, \n",
    "            batch['channels'].long(),\n",
    "            placeholder)#.to('cuda:0'))\n",
    "        \n",
    "        logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "        fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        mean_loss += loss.item()\n",
    "        acc_step += 1\n",
    "        steps += 1\n",
    "        # raise\n",
    "        if acc_step != 0 and acc_step % acc_size == 0:\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad()\n",
    "            if steps % 100 == 0:\n",
    "                print('Loss/train\\t{}'.format(mean_loss / acc_size))\n",
    "            writer.add_scalar('Loss/train', mean_loss / acc_size, steps)\n",
    "            mean_loss = 0\n",
    "        if steps != 0 and steps % 1000 == 0:\n",
    "            der = 0\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_loader:\n",
    "                        # batch = test_dataset.__getitem__(i)\n",
    "                        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "                        ae, label = model_test(\n",
    "                            batch['anchor'],#.to('cuda:0'), \n",
    "                            None, \n",
    "                            batch['channels'].long(),#.to('cuda:0'),\n",
    "                            placeholder)\n",
    "                        # loss_positive = loss_fct(ae, pe)\n",
    "                        # loss_negative = loss_fct(ae, ne)\n",
    "                        logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "                        fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "                        loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "                        loss = loss.mean() / acc_size\n",
    "                        der += loss\n",
    "                der /= len(test_loader)\n",
    "                writer.add_scalar('Loss/test', der, steps)\n",
    "\n",
    "                print('Loss: {}\\t'.format(der))\n",
    "            except:\n",
    "                raise\n",
    "            torch.save(model_test.module.state_dict(), 'models2/step_{}.pt'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d4fe0f3-a703-4789-af35-65ab6952de3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5176, device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f1387f3-dfc2-4af0-b5d9-b9e7c6852b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159219"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02da7a52-ca20-4822-ac49-62be4a2b16b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'value': array([[ -3.85031008,   2.85196812,   2.07325583, ...,  -7.50037225,\n",
       "        -10.90961471,  -8.02874688],\n",
       "       [-14.41600966,  -6.85561872,  -1.99783744, ..., -12.02037489,\n",
       "        -20.83239401,  -7.28345165],\n",
       "       [-22.68984145, -16.19871822,  -5.15646806, ..., -17.4048751 ,\n",
       "        -25.79506833, -21.20112015],\n",
       "       ...,\n",
       "       [  0.83328995,   6.0946769 ,  -1.01211029, ...,   5.56320695,\n",
       "          3.40607593,   9.95040555],\n",
       "       [ -5.23044887,   2.98819828,  -2.53847765, ...,   1.96995798,\n",
       "          1.19625315,   6.24915094],\n",
       "       [ -6.41559363,   0.44634677,  -3.84797447, ...,  -2.32357481,\n",
       "         -2.30819229,  -0.28246068]]), 'date': 's004_2016_08_25', 'id': '147_00014747', 'ref_type': '01_tcp_ar', 'channels': ['FP1', 'FP2', 'FZ', 'FCZ', 'CZ', 'PZ', 'O1', 'O2', 'F3', 'F4', 'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/home/data/TUH_pretrain.filtered_1_40.splited/2990_174000.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ef8b9-82ed-439f-be4e-584d8982a929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0279c01-302c-4855-8a60-07850cfd24f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2a8a8-ed8e-454b-bf8d-e08fb828c6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec02d4-b1d2-431d-8eb6-666144c31cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be2c10bd-2805-46f5-8b4f-509c7484df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "lr_d = 1e-5\n",
    "acc_size = 1\n",
    "training_epochs1 = 150000 // len(train_loader)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr_d)\n",
    "\n",
    "model_test = torch.nn.DataParallel(model)\n",
    "model_test.to('cuda:0')\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c597706-cec7-4076-bc6c-a7a2002f82dd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train\t1.8929529190063477\n",
      "Loss/train\t1.9144232273101807\n",
      "Loss/train\t1.8872368335723877\n",
      "Loss/train\t1.898066759109497\n",
      "Loss/train\t1.9088211059570312\n",
      "Loss/train\t1.896066665649414\n",
      "Loss/train\t1.903018593788147\n",
      "Loss/train\t1.8914568424224854\n",
      "Loss/train\t1.903407096862793\n",
      "Loss: 1.7999563217163086\t\n",
      "Loss/train\t1.8804712295532227\n",
      "Loss/train\t1.8972877264022827\n",
      "Loss/train\t1.8831760883331299\n",
      "Loss/train\t1.9031308889389038\n",
      "Loss/train\t1.8904520273208618\n",
      "Loss/train\t1.9119493961334229\n",
      "Loss/train\t1.9052908420562744\n",
      "Loss/train\t1.896553874015808\n",
      "Loss/train\t1.9152153730392456\n",
      "Loss/train\t1.869958758354187\n",
      "Loss: 1.7969849109649658\t\n",
      "Loss/train\t1.8917416334152222\n",
      "Loss/train\t1.9191652536392212\n",
      "Loss/train\t1.8704347610473633\n",
      "Loss/train\t1.8648254871368408\n",
      "Loss/train\t1.8790819644927979\n",
      "Loss/train\t1.910555124282837\n",
      "Loss/train\t1.8742694854736328\n",
      "Loss/train\t1.905527949333191\n",
      "Loss/train\t1.8932743072509766\n",
      "Loss/train\t1.8955141305923462\n",
      "Loss: 1.7965463399887085\t\n",
      "Loss/train\t1.860345482826233\n",
      "Loss/train\t1.887194037437439\n",
      "Loss/train\t1.906114935874939\n",
      "Loss/train\t1.8906548023223877\n",
      "Loss/train\t1.8939846754074097\n",
      "Loss/train\t1.9004894495010376\n",
      "Loss/train\t1.8951305150985718\n",
      "Loss/train\t1.871289610862732\n",
      "Loss/train\t1.8848812580108643\n",
      "Loss/train\t1.9144881963729858\n",
      "Loss: 1.7985378503799438\t\n",
      "Loss/train\t1.8898632526397705\n",
      "Loss/train\t1.8724571466445923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 42\u001b[0m mean_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m acc_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     44\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(training_epochs1):\n",
    "    mean_loss = 0\n",
    "    acc_step = 0\n",
    "    for batch in train_loader:\n",
    "        # batch = train_dataset.__getitem__(i)\n",
    "        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "        ae, label = model_test(\n",
    "            batch['anchor'],#.to('cuda:0'), \n",
    "            batch['mask'], \n",
    "            batch['channels'].long(),\n",
    "            placeholder)#.to('cuda:0'))\n",
    "        # loss_value = loss_fct(output, batch['labels'].to('cuda:0'))\n",
    "        # loss_positive = loss_fct(ae, pe)\n",
    "        # loss_negative = loss_fct(ae, ne)\n",
    "        reshaped_indexed_real = []\n",
    "        reshaped_indexed_pred = []\n",
    "        reshaped_indexed_negative = []\n",
    "        for b_i in range(ae.shape[0]):\n",
    "            reshaped_indexed_pred.append(ae[b_i][batch['mask'][b_i][::10]][None])\n",
    "            reshaped_indexed_real.append(label[b_i][batch['mask'][b_i][::10]][None])\n",
    "            reshaped_indexed_negative.append(label[b_i][(batch['mask'][b_i] + 20) % 132][None])\n",
    "        reshaped_indexed_pred = torch.cat(reshaped_indexed_pred, 0)\n",
    "        reshaped_indexed_real = torch.cat(reshaped_indexed_real, 0)\n",
    "        reshaped_indexed_negative = torch.cat(reshaped_indexed_negative, 0)\n",
    "        # raise\n",
    "        loss = cosloss(\n",
    "            reshaped_indexed_pred, \n",
    "            reshaped_indexed_real, \n",
    "            reshaped_indexed_negative.reshape(\n",
    "                reshaped_indexed_negative.shape[0], \n",
    "                reshaped_indexed_negative.shape[1] // 5, \n",
    "                reshaped_indexed_negative.shape[1] // 10, \n",
    "                reshaped_indexed_negative.shape[2]))\n",
    "        # loss = loss_func(reshaped_indexed_pred[indexes_fine][:, :, :2], reshaped_indexed_real[indexes_fine][:, :, :2].to('cuda:0'))\n",
    "\n",
    "        # hard_loss = loss[loss > 0.0]\n",
    "        # if (len(hard_loss) == 0):\n",
    "        #     hard_loss = loss\n",
    "        # hard_loss = loss\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        mean_loss += loss.item()\n",
    "        acc_step += 1\n",
    "        steps += 1\n",
    "        # raise\n",
    "        if acc_step != 0 and acc_step % acc_size == 0:\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad()\n",
    "            if steps % 100 == 0:\n",
    "                print('Loss/train\\t{}'.format(mean_loss / acc_size))\n",
    "            writer.add_scalar('Loss/train', mean_loss / acc_size, steps)\n",
    "            mean_loss = 0\n",
    "        if steps != 0 and steps % 1000 == 0:\n",
    "            der = 0\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_loader:\n",
    "                        # batch = test_dataset.__getitem__(i)\n",
    "                        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "                        ae, label = model_test(\n",
    "                            batch['anchor'],#.to('cuda:0'), \n",
    "                            batch['mask'], \n",
    "                            batch['channels'].long(),#.to('cuda:0'),\n",
    "                            placeholder)\n",
    "                        # loss_positive = loss_fct(ae, pe)\n",
    "                        # loss_negative = loss_fct(ae, ne)\n",
    "                        reshaped_indexed_real = []\n",
    "                        reshaped_indexed_pred = []\n",
    "                        reshaped_indexed_negative = []\n",
    "                        for b_i in range(ae.shape[0]):\n",
    "                            reshaped_indexed_pred.append(ae[b_i][batch['mask'][b_i][::10]][None])\n",
    "                            reshaped_indexed_real.append(label[b_i][batch['mask'][b_i][::10]][None])\n",
    "                            reshaped_indexed_negative.append(label[b_i][(batch['mask'][b_i] + 20) % 132][None])\n",
    "                        reshaped_indexed_pred = torch.cat(reshaped_indexed_pred, 0)\n",
    "                        reshaped_indexed_real = torch.cat(reshaped_indexed_real, 0)\n",
    "                        reshaped_indexed_negative = torch.cat(reshaped_indexed_negative, 0)\n",
    "\n",
    "                        loss = cosloss(\n",
    "                            reshaped_indexed_pred, \n",
    "                            reshaped_indexed_real, \n",
    "                            reshaped_indexed_negative.reshape(\n",
    "                                reshaped_indexed_negative.shape[0], \n",
    "                                reshaped_indexed_negative.shape[1] // 5, \n",
    "                                reshaped_indexed_negative.shape[1] // 10, \n",
    "                                reshaped_indexed_negative.shape[2]))\n",
    "\n",
    "                        loss = loss.mean() / acc_size\n",
    "                        der += loss\n",
    "                der /= len(test_loader)\n",
    "                writer.add_scalar('Loss/test', der, steps)\n",
    "\n",
    "                print('Loss: {}\\t'.format(der))\n",
    "            except:\n",
    "                raise\n",
    "            torch.save(model_test.module.state_dict(), 'models/step_{}.pt'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5a95a-1cb9-4553-9799-3550959cea67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
