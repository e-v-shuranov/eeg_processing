{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03477f44-46c2-4a22-aaee-a67878c1816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  7 14:34:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   31C    P8    30W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8    20W / 350W |   5606MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   4156900      C   /usr/bin/python3                 5603MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e513c8-c521-4ac4-b93c-bea7dbb4eac9",
   "metadata": {},
   "source": [
    "##### %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de61d6ab-33e9-40ef-b448-6686a5a4e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ['http_proxy'] = \"http://127.0.0.1:3128\"\n",
    "# os.environ['https_proxy'] = \"http://127.0.0.1:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab062da-1f4d-4f54-965f-49e519bb897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a029d2ef-c060-410a-9c98-aa48d86c7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e1e8bc-99d9-4968-9956-fe13fc4433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bert_conv_custom import BertConfig, BertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26801a7a-b4e6-4faf-8da1-b8d953dd7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c443a-6995-43ca-ac1d-43cfe5ec376a",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef112d9-8b15-407a-b735-cc584072cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposeCustom(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransposeCustom, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.transpose(x, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411dce92-23fd-4258-ab4c-73b9f68f8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = BertConfig(is_decoder=True, \n",
    "#                     add_cross_attention=True,\n",
    "#                     ff_layer='conv',\n",
    "#                     conv_kernel=1,\n",
    "#                     conv_kernel_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711ae813-492d-4fe1-89ee-8315cb43617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_span_from_seeds(seeds, span, total=None):\n",
    "    inds = list()\n",
    "    for seed in seeds:\n",
    "        for i in range(seed, seed + span):\n",
    "            if total is not None and i >= total:\n",
    "                break\n",
    "            elif i not in inds:\n",
    "                inds.append(int(i))\n",
    "    return np.array(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d78b6b1-0a91-4706-92ca-f52a791ea753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_mask(shape, p, total, span, allow_no_inds=False):\n",
    "    # num_mask_spans = np.sum(np.random.rand(total) < p)\n",
    "    # num_mask_spans = int(p * total)\n",
    "    mask = torch.zeros(shape, requires_grad=False, dtype=torch.bool)\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        mask_seeds = list()\n",
    "        while not allow_no_inds and len(mask_seeds) == 0 and p > 0:\n",
    "            mask_seeds = np.nonzero(np.random.rand(total) < p)[0]\n",
    "\n",
    "        mask[i, _make_span_from_seeds(mask_seeds, span, total=total)] = True\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e79430c-e70e-4e42-8f35-3bbae19c2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        position = (position.T - position).T / max_len\n",
    "        self.register_buffer('rel_position', position)\n",
    "        \n",
    "        self.conv = torch.nn.Conv1d(max_len, d_model, 25, padding=25 // 2, groups=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        rel_pos = self.conv(self.rel_position[:x.size(1), :x.size(1)][None])[0].T\n",
    "        print(rel_pos.shape)\n",
    "        x = x + rel_pos\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ade54a7-ca7a-48c7-bb53-85a0f741d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGEmbedder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGEmbedder, self).__init__()\n",
    "        config = BertConfig(is_decoder=False, \n",
    "                    add_cross_attention=False,\n",
    "                    ff_layer='linear',\n",
    "                    hidden_size=512,\n",
    "                    num_attention_heads=8,\n",
    "                    num_hidden_layers=8,\n",
    "                    conv_kernel=1,\n",
    "                    conv_kernel_num=1)\n",
    "        self.model = BertEncoder(config)\n",
    "        \n",
    "        self.pos_e = PositionalEncoding(512, max_len=6000)\n",
    "        self.ch_embedder = torch.nn.Embedding(len(mitsar_chls), 512)\n",
    "        self.ch_norm = torch.nn.LayerNorm(512)\n",
    "        \n",
    "        self.input_norm = torch.nn.LayerNorm(2)\n",
    "        self.input_embedder = torch.nn.Sequential(\n",
    "            TransposeCustom(),\n",
    "            torch.nn.Conv1d(2, 32, 5, 2, padding=0),\n",
    "            torch.nn.Conv1d(32, 64, 5, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(64 // 2, 64),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(64, 128, 3, 2, padding=0),\n",
    "            torch.nn.Conv1d(128, 196, 3, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(196 // 2, 196),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(196, 256, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(256, 384, 5, 1, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(384 // 2, 384),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(384, 512, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(512, 512, 1, 1, padding=0),\n",
    "            torch.nn.GroupNorm(512 // 2, 512),\n",
    "            torch.nn.GELU(),\n",
    "            TransposeCustom(),\n",
    "        # torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        # self.input_norm = torch.nn.LayerNorm(10)\n",
    "        # self.output_embedder = torch.nn.Conv1d(512, 512, 1)\n",
    "        self.output_embedder = torch.nn.Linear(512, 512)\n",
    "        self.transpose = TransposeCustom()\n",
    "        \n",
    "        self.mask_embedding = torch.nn.Parameter(torch.normal(0, 512**(-0.5), size=(512,)),\n",
    "                                                   requires_grad=True)\n",
    "        self.classification = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 2),\n",
    "            torch.nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "    def single_forward(self, inputs, attention_mask, ch_vector, placeholder):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        # print(embedding.shape, ch_embedding.shape)\n",
    "        embedding += ch_embedding\n",
    "        # embedding = self.ch_norm(embedding)\n",
    "        # we lost some channel specific information\n",
    "        # embedding_unmasked = embedding.clone()\n",
    "        \n",
    "        # mask = _make_mask((embedding.shape[0], embedding.shape[1]), 0.05, embedding.shape[1], 10)\n",
    "        # embedding[mask] = self.mask_embedding\n",
    "        \n",
    "        # for b_i in range(embedding.shape[0]):\n",
    "        #     embedding_masked[b_i][mask[b_i]] = self.mask_embedding\n",
    "        \n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "        encoder_output = self.output_embedder(encoder_output)\n",
    "        # encoder_output = self.transpose(encoder_output)\n",
    "        return encoder_output[:, 0], None\n",
    "    \n",
    "    def forward(self, a, mask, ch_vector, placeholder):\n",
    "        a_downsampled_embedding, label = self.single_forward(a, mask, ch_vector, placeholder)\n",
    "        pred = self.classification(a_downsampled_embedding)\n",
    "        return pred, label\n",
    "    \n",
    "    def infer(self, a, ch_vector, placeholder):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        # print(embedding.shape, ch_embedding.shape)\n",
    "        embedding += ch_embedding\n",
    "        # embedding = self.ch_norm(embedding)\n",
    "            \n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "        \n",
    "        encoder_output = self.output_embedder(self.transpose(encoder_output))\n",
    "        return encoder_output, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77774c12-ce6f-47f6-87fe-9b158fdcfdee",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d6c08d-49a6-4789-a24f-929cb2bd294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_negatives(z):\n",
    "    \"\"\"Generate negative samples to compare each sequence location against\"\"\"\n",
    "    num_negatives = 20\n",
    "    batch_size, feat, full_len = z.shape\n",
    "    z_k = z.permute([0, 2, 1]).reshape(-1, feat)\n",
    "    with torch.no_grad():\n",
    "        # candidates = torch.arange(full_len).unsqueeze(-1).expand(-1, self.num_negatives).flatten()\n",
    "        negative_inds = torch.randint(0, full_len-1, size=(batch_size, full_len * num_negatives))\n",
    "        # From wav2vec 2.0 implementation, I don't understand\n",
    "        # negative_inds[negative_inds >= candidates] += 1\n",
    "\n",
    "        for i in range(1, batch_size):\n",
    "            negative_inds[i] += i * full_len\n",
    "\n",
    "    z_k = z_k[negative_inds.view(-1)].view(batch_size, full_len, num_negatives, feat)\n",
    "    return z_k, negative_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534e0a28-d364-424b-95ea-ba9aef8969e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_similarity( z, c, negatives):\n",
    "    c = c[..., :].permute([0, 2, 1]).unsqueeze(-2)\n",
    "    z = z.permute([0, 2, 1]).unsqueeze(-2)\n",
    "\n",
    "    # In case the contextualizer matches exactly, need to avoid divide by zero errors\n",
    "    negative_in_target = (c == negatives).all(-1)\n",
    "    targets = torch.cat([c, negatives], dim=-2)\n",
    "\n",
    "    logits = torch.nn.functional.cosine_similarity(z, targets, dim=-1) / 0.1\n",
    "    if negative_in_target.any():\n",
    "        logits[1:][negative_in_target] = float(\"-inf\")\n",
    "\n",
    "    return logits.view(-1, logits.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9679b5-eb5e-45e8-a042-88c24489b697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39fbf98e-eee4-4232-b16d-33c35d176f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(ts):\n",
    "    start_shift = np.random.choice(range(10))\n",
    "    downsampling = 2\n",
    "    indices = np.random.choice(np.array(list(range(110)))[start_shift::10][::downsampling], 5, replace=False)\n",
    "    masked_idx = []\n",
    "    for i in indices:\n",
    "        masked_idx.extend(range(i, i+10))\n",
    "\n",
    "    masked_idx = np.array(masked_idx)\n",
    "    \n",
    "    # mask = np.ones((6000, 2))\n",
    "    # # desync some masked channels\n",
    "    # ts_masked = ts.copy()\n",
    "    # if np.random.choice([0, 1], p=[0.7, 0.3]):\n",
    "    #     ts_masked[masked_idx, np.random.choice([0, 1])] *= 0\n",
    "    # else:\n",
    "    #     ts_masked[masked_idx] *= 0\n",
    "        \n",
    "    return None, masked_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368cce54-d9fc-4d65-9341-34b1fadebe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({0: tensor(2.4250), 1: tensor(1.9767)},\n",
    "#  {0: tensor(66.8642), 1: tensor(46.8854)})\n",
    "\n",
    "mean_dict = {0: (0.9631),\n",
    " 1: (1.0248),\n",
    " 2: (1.3041),\n",
    " 3: (0.),\n",
    " 4: (1.5822),\n",
    " 5: (1.7250),\n",
    " 6: (0.9935),\n",
    " 7: (0.9548),\n",
    " 8: (0.7488),\n",
    " 9: (1.3948),\n",
    " 10: (0.8879),\n",
    " 11: (1.0527),\n",
    " 12: (1.3401),\n",
    " 13: (1.5541),\n",
    " 14: (1.2600),\n",
    " 15: (1.0487),\n",
    " 16: (0.7529),\n",
    " 17: (1.6566),\n",
    " 18: (0.9272),\n",
    " 19: (1.2238),\n",
    " 20: (1.2619),\n",
    " 21: (1.5236)}\n",
    "\n",
    "std_dict = {0: (64.1294),\n",
    " 1: (64.1984),\n",
    " 2: (45.9215),\n",
    " 3: (0.),\n",
    " 4: (45.1312),\n",
    " 5: (51.7621),\n",
    " 6: (43.5150),\n",
    " 7: (39.7182),\n",
    " 8: (46.8787),\n",
    " 9: (49.0797),\n",
    " 10: (52.2342),\n",
    " 11: (51.9236),\n",
    " 12: (50.7353),\n",
    " 13: (52.1277),\n",
    " 14: (48.8627),\n",
    " 15: (42.7040),\n",
    " 16: (46.5815),\n",
    " 17: (60.2403),\n",
    " 18: (41.6082),\n",
    " 19: (44.6035),\n",
    " 20: (82.8107),\n",
    " 21: (53.5717)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "403a5a1e-54dc-4134-b747-13da890c0c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:34:57.399139: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cff7e071-49f9-4203-881d-a9bb00c7ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEST(torch.utils.data.Dataset):\n",
    "    def __init__(self, main, labels, norm):\n",
    "        super(TEST, self).__init__()\n",
    "        self.main = main\n",
    "        self.label = labels\n",
    "        self.norm = norm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.main)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # sample = torch.from_numpy(np.load(self.meta.iloc[idx]['path'])[:6000].astype(np.float32)).clone()\n",
    "        sample = np.copy(self.main[idx])\n",
    "        # sample = butter_bandpass_filter_v2(sample, 1, 40, 100)\n",
    "        # sample_label = torch.tensor(np.copy(self.label[idx]))-1#torch.tensor(1 if self.main[idx]['label'] == 'work' else 0)\n",
    "        sample_label = torch.tensor(0) if self.label[idx] == 1 else torch.tensor(1)\n",
    "        # sample_label = label_map[sample['label']]\n",
    "        \n",
    "        channels = [mitsar_chls.index('T4'), mitsar_chls.index('T6')]\n",
    "        sample = sample[:, [HSE_chls.index('T7'), HSE_chls.index('T8')]]\n",
    "        # sample_min, sample_max = sample.min(0), sample.max(0)\n",
    "        # sample = (sample - sample_min) / (sample_max - sample_min)\n",
    "        sample[:, 0] -= self.norm['mean'][HSE_chls.index('T7')]\n",
    "        sample[:, 1] -= self.norm['mean'][HSE_chls.index('T8')]\n",
    "        sample[:, 0] /= self.norm['std'][HSE_chls.index('T7')]\n",
    "        sample[:, 1] /= self.norm['std'][HSE_chls.index('T8')]\n",
    "        \n",
    "        # sample = butter_bandpass_filter_v2(sample, 1, 40, 100)\n",
    "        sample = torch.from_numpy(sample[:3000].astype(np.float32)).clone()\n",
    "        return {'anchor': sample, \n",
    "                'label': sample_label,\n",
    "                'channels': torch.tensor(channels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f2b3be5-d7e8-4f5e-8164-8662763ec34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HSE_chls = ['Fp1', 'Fz', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7',\n",
    "    'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'CP6',\n",
    "    'CP2', 'Cz', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'FP2']\n",
    "\n",
    "HSE_chls = [i.upper() for i in HSE_chls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03846c9f-2eee-4596-b292-27e90a4f85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitsar_chls = ['Fp1', 'Fp2', 'FZ', 'FCz', 'Cz', 'Pz', 'O1', 'O2', 'F3', 'F4', \n",
    "               'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n",
    "mitsar_chls = [i.upper() for i in mitsar_chls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550bf319-7fb2-4d4e-a3b9-cd198b678cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('/home/data/HSE_exp/processed/v2/train_signal.npy', allow_pickle=True)\n",
    "test_data = np.load('/home/data/HSE_exp/processed/v2/test_signal.npy', allow_pickle=True)\n",
    "\n",
    "train_label = np.load('/home/data/HSE_exp/processed/v2/train_label.npy', allow_pickle=True)\n",
    "test_label = np.load('/home/data/HSE_exp/processed/v2/test_label.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9980a57-1911-49f6-9108-9b5cf51e4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [val for i, val in enumerate(train_data) if train_label[i] not in [0, 2]]\n",
    "train_label = [val for i, val in enumerate(train_label) if val not in [0, 2]]\n",
    "\n",
    "test_data = [val for i, val in enumerate(test_data) if test_label[i]  not in [0, 2]]\n",
    "test_label = [val for i, val in enumerate(test_label) if val  not in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6ac5c13-facf-4c8c-88b8-53aab90b33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.array([butter_bandpass_filter_v2(i, 1, 40, 100) for i in train_data])\n",
    "# test_data = np.array([butter_bandpass_filter_v2(i, 1, 40, 100) for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1e5381-933e-4580-880c-37bf7c3cb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_meta = {'mean': [], 'std': []}\n",
    "channels_meta['mean'] = (np.concatenate([train_data, test_data]).reshape(np.concatenate([train_data, test_data]).shape[0] * np.concatenate([train_data, test_data]).shape[1], -1).mean(0))\n",
    "channels_meta['std'] = (np.concatenate([train_data, test_data]).reshape(np.concatenate([train_data, test_data]).shape[0] * np.concatenate([train_data, test_data]).shape[1], -1).std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe28c494-df72-438f-a39e-b95ebbdbe724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3 = np.load('/home/data/HSE_exp/processed/v2/train_signal.3.npy', allow_pickle=True)\n",
    "test_data3 = np.load('/home/data/HSE_exp/processed/v2/test_signal.3.npy', allow_pickle=True)\n",
    "\n",
    "train_label3 = np.load('/home/data/HSE_exp/processed/v2/train_label.3.npy', allow_pickle=True)\n",
    "test_label3 = np.load('/home/data/HSE_exp/processed/v2/test_label.3.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f30dc6c-928f-4ce7-afd5-50edffa81f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3 = [val for i, val in enumerate(train_data3) if train_label3[i] not in [0, 2]]\n",
    "train_label3 = [val for i, val in enumerate(train_label3) if val not in [0, 2]]\n",
    "\n",
    "test_data3 = [val for i, val in enumerate(test_data3) if test_label3[i]  not in [0, 2]]\n",
    "test_label3 = [val for i, val in enumerate(test_label3) if val  not in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c45d04e6-f23c-446e-8c0d-4a94f4b4fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_meta3 = {'mean': [], 'std': []}\n",
    "channels_meta3['mean'] = (np.concatenate([train_data3, test_data3]).reshape(np.concatenate([train_data3, test_data3]).shape[0] * np.concatenate([train_data3, test_data3]).shape[1], -1).mean(0))\n",
    "channels_meta3['std'] = (np.concatenate([train_data3, test_data3]).reshape(np.concatenate([train_data3, test_data3]).shape[0] * np.concatenate([train_data3, test_data3]).shape[1], -1).std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef9bce4a-7c8d-4afb-9cc2-56348e7a72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_data = data[:len(data)//100 * 90]\n",
    "# train_data = [i for i in train_data if i['eeg'].shape[0] > 500]\n",
    "# test_data = data[len(data)//100 * 90:]\n",
    "# test_data = [i for i in test_data if i['eeg'].shape[0] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1736eb7e-983a-4b39-9c75-84fbb3fbc480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 139)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f42572a-b72c-4b5c-823c-1bdadbc1d4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TEST(test_data, test_label, channels_meta)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a413d97-8fc1-47a6-b137-3ac8247cf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitsar_chls = ['Fp1', 'Fp2', 'FZ', 'FCz', 'Cz', 'Pz', 'O1', 'O2', 'F3', 'F4', \n",
    "               'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n",
    "mitsar_chls = [i.upper() for i in mitsar_chls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a48eb7-0727-43ea-bedb-cd419ecd6532",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95ba1c89-cf1d-48d6-a6dd-4f8b0432ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02c49688-e680-406f-9de5-2eae316eeb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['classification.0.weight', 'classification.0.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../../../../Pretraining/v5/models2/step_159000.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50e2bc04-d8ab-4095-8081-c6e8d56fd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class NoamLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, d_model=512):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d_model = d_model\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = max(1, self.last_epoch)\n",
    "        factor = min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # scale = self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # return [base_lr * scale for base_lr in self.base_lrs]\n",
    "        return [base_lr * self.d_model ** (-0.5) * factor for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cd39442-574d-489d-9cae-2886fa7b2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "def cosloss(anchor, real, negative):\n",
    "    a = torch.exp(cossim(anchor, real)) / 0.1\n",
    "    b = sum([torch.exp(cossim(anchor, negative[:, n])) / 0.1 for n in range(negative.shape[1])]) + 1e-6\n",
    "    return -torch.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e28e456c-e80d-4cf6-ad0b-4c6af1427908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    random.seed(torch_seed + worker_id)\n",
    "    np.random.seed((torch_seed + worker_id) % 2**30)\n",
    "\n",
    "\n",
    "train_dataset = TEST(train_data, train_label, channels_meta)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "test_dataset = TEST(test_data, test_label, channels_meta)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "test_dataset3 = TEST(test_data3, test_label3, channels_meta3)\n",
    "test_loader3 = torch.utils.data.DataLoader(test_dataset3, batch_size=32, shuffle=False, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bc0dce6-c149-4043-bf79-d84a337177fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "lr_d = 5e-6\n",
    "acc_size = 1\n",
    "training_epochs1 = 15000 // len(train_loader)\n",
    "\n",
    "# model_test = torch.nn.DataParallel(model)\n",
    "# optim = torch.optim.AdamW(model.parameters(), lr=lr_d)\n",
    "optim = torch.optim.AdamW([{'params': model.model.parameters(), 'lr': 1e-7},\n",
    "                          {'params': model.classification.parameters(), 'lr': 1e-4}])\n",
    "# scheduler = NoamLR(optim, 3000, 512)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=lr_d, total_steps=training_epochs1*len(train_loader))\n",
    "model.to('cuda:0')\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25684f3b-1b46-41f3-ab64-342dd82ffb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1500, 15000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), training_epochs1, training_epochs1 * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96e14cca-9b1c-43a6-a38c-2f0715bfc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a8ee36c-93ab-408d-9171-951b2d01c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()(batch['anchor'][None], batch['mask'][None], batch['channels'][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d301d68b-775a-47a1-a1a9-ff2ff4d20b3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6289346218109131\t\n",
      "Loss: 0.5992487668991089\t\n",
      "(array([0.52112676, 0.52631579]), array([0.578125, 0.46875 ]), array([0.54814815, 0.49586777]), array([64, 64]))\n",
      "Loss: 0.6803186535835266\t\n",
      "Loss: 0.4345097839832306\t\n",
      "Loss: 0.5174616575241089\t\n",
      "(array([0.57575758, 0.58064516]), array([0.59375, 0.5625 ]), array([0.58461538, 0.57142857]), array([64, 64]))\n",
      "Loss: 0.6768562197685242\t\n",
      "Loss: 0.5666288137435913\t\n",
      "Loss: 0.53565913438797\t\n",
      "(array([0.55172414, 0.54285714]), array([0.5    , 0.59375]), array([0.52459016, 0.56716418]), array([64, 64]))\n",
      "Loss: 0.7066055536270142\t\n",
      "Loss: 0.5124634504318237\t\n",
      "Loss: 0.5562436580657959\t\n",
      "(array([0.578125, 0.578125]), array([0.578125, 0.578125]), array([0.578125, 0.578125]), array([64, 64]))\n",
      "Loss: 0.6942340135574341\t\n",
      "Loss: 0.5782976746559143\t\n",
      "Loss: 0.506091296672821\t\n",
      "(array([0.578125, 0.578125]), array([0.578125, 0.578125]), array([0.578125, 0.578125]), array([64, 64]))\n",
      "Loss: 0.6966123580932617\t\n",
      "Loss: 0.47986263036727905\t\n",
      "Loss: 0.46121659874916077\t\n",
      "(array([0.55172414, 0.54285714]), array([0.5    , 0.59375]), array([0.52459016, 0.56716418]), array([64, 64]))\n",
      "Loss: 0.7518408298492432\t\n",
      "Loss: 0.38607171177864075\t\n",
      "Loss: 0.4480200409889221\t\n",
      "(array([0.61016949, 0.5942029 ]), array([0.5625  , 0.640625]), array([0.58536585, 0.61654135]), array([64, 64]))\n",
      "Loss: 0.7108815908432007\t\n",
      "Loss: 0.47923949360847473\t\n",
      "Loss: 0.3964676558971405\t\n",
      "(array([0.53968254, 0.53846154]), array([0.53125 , 0.546875]), array([0.53543307, 0.54263566]), array([64, 64]))\n",
      "Loss: 0.7491998076438904\t\n",
      "Loss: 0.3579421937465668\t\n",
      "Loss: 0.3368000388145447\t\n",
      "(array([0.58064516, 0.57575758]), array([0.5625 , 0.59375]), array([0.57142857, 0.58461538]), array([64, 64]))\n",
      "Loss: 0.7208026051521301\t\n",
      "Loss: 0.38490569591522217\t\n",
      "Loss: 0.39557328820228577\t\n",
      "(array([0.56666667, 0.55882353]), array([0.53125, 0.59375]), array([0.5483871 , 0.57575758]), array([64, 64]))\n",
      "Loss: 0.7355438470840454\t\n",
      "Loss: 0.3228726387023926\t\n",
      "Loss: 0.39370623230934143\t\n",
      "(array([0.54098361, 0.53731343]), array([0.515625, 0.5625  ]), array([0.528     , 0.54961832]), array([64, 64]))\n",
      "Loss: 0.7505550384521484\t\n",
      "Loss: 0.4115026593208313\t\n",
      "Loss: 0.3472124934196472\t\n",
      "(array([0.57142857, 0.55555556]), array([0.5  , 0.625]), array([0.53333333, 0.58823529]), array([64, 64]))\n",
      "Loss: 0.7398498058319092\t\n",
      "Loss: 0.37674814462661743\t\n",
      "Loss: 0.3457006514072418\t\n",
      "(array([0.57627119, 0.56521739]), array([0.53125 , 0.609375]), array([0.55284553, 0.58646617]), array([64, 64]))\n",
      "Loss: 0.7405005693435669\t\n",
      "Loss: 0.3851328492164612\t\n",
      "Loss: 0.3968232274055481\t\n",
      "(array([0.55555556, 0.55384615]), array([0.546875, 0.5625  ]), array([0.5511811 , 0.55813953]), array([64, 64]))\n",
      "Loss: 0.7395544648170471\t\n",
      "Loss: 0.3760882318019867\t\n",
      "Loss: 0.3787240982055664\t\n",
      "(array([0.55932203, 0.55072464]), array([0.515625, 0.59375 ]), array([0.53658537, 0.57142857]), array([64, 64]))\n",
      "Loss: 0.7543550729751587\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs1):\n",
    "    mean_loss = 0\n",
    "    acc_step = 0\n",
    "    for batch in train_loader:\n",
    "        # batch = train_dataset.__getitem__(i)\n",
    "        optim.zero_grad()\n",
    "        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "        ae, _ = model(\n",
    "            batch['anchor'].to('cuda:0'), \n",
    "            None, \n",
    "            batch['channels'].long().to('cuda:0'),\n",
    "            placeholder.to('cuda:0'))\n",
    "        loss = loss_func(ae.view(-1, 2), batch['label'].to('cuda:0').long())\n",
    "        # loss = loss.mean() / acc_size\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        mean_loss = loss.item()\n",
    "        acc_step += 1\n",
    "        steps += 1\n",
    "        optim.step()\n",
    "        # scheduler.step()\n",
    "        if steps % 500 == 0:\n",
    "            print('Loss: {}\\t'.format(mean_loss))\n",
    "        \n",
    "        if steps != 0 and steps % 1000 == 0:\n",
    "            der = 0\n",
    "            preds = []\n",
    "            reals = []\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_loader:\n",
    "                        # batch = test_dataset.__getitem__(i)\n",
    "                        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "                        ae, label = model(\n",
    "                            batch['anchor'].to('cuda:0'), \n",
    "                            None, \n",
    "                            batch['channels'].long().to('cuda:0'),\n",
    "                            placeholder.to('cuda:0'))\n",
    "                        # loss_positive = loss_fct(ae, pe)\n",
    "                        # loss_negative = loss_fct(ae, ne)\n",
    "                        reals.extend(batch['label'])\n",
    "                        preds.extend(ae.view(-1, 2))\n",
    "                        loss = loss_func(ae.view(-1, 2), batch['label'].to('cuda:0').long())\n",
    "\n",
    "                        loss = loss.mean() / acc_size\n",
    "                        der += loss\n",
    "                der /= len(test_loader)\n",
    "                writer.add_scalar('Loss/test', der, steps)\n",
    "                \n",
    "                \n",
    "                reals = np.array([i.tolist() for i in reals])\n",
    "                preds = np.array([i.tolist() for i in preds])\n",
    "                # preds[np.where(preds < 0.5)] = 0\n",
    "                # preds[np.where(preds >= 0.5)] = 1\n",
    "                print(precision_recall_fscore_support(reals, preds.argmax(-1)))\n",
    "\n",
    "                print('Loss: {}\\t'.format(der))\n",
    "            except:\n",
    "                raise\n",
    "            # torch.save(model_test.module.state_dict(), '{}/step_{}.der_{}.pt'.format(model_path, steps, round(der, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ef8b9-82ed-439f-be4e-584d8982a929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0279c01-302c-4855-8a60-07850cfd24f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.50485437, 0.72      ]), array([0.88135593, 0.26086957]), array([0.64197531, 0.38297872]), array([59, 69]))\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "reals = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader3:\n",
    "        # batch = test_dataset.__getitem__(i)\n",
    "        placeholder = torch.zeros((batch['anchor'].shape[0], 1, 512)) - 5\n",
    "        ae, label = model(\n",
    "            batch['anchor'].to('cuda:0'), \n",
    "            None, \n",
    "            batch['channels'].long().to('cuda:0'),\n",
    "            placeholder.to('cuda:0'))\n",
    "        # loss_positive = loss_fct(ae, pe)\n",
    "        # loss_negative = loss_fct(ae, ne)\n",
    "        reals.extend(batch['label'])\n",
    "        preds.extend(ae.view(-1, 2))\n",
    "        loss = loss_func(ae.view(-1, 2), batch['label'].to('cuda:0').long())\n",
    "\n",
    "        loss = loss.mean() / acc_size\n",
    "        der += loss\n",
    "der /= len(test_loader)\n",
    "writer.add_scalar('Loss/test', der, steps)\n",
    "\n",
    "\n",
    "reals = np.array([i.tolist() for i in reals])\n",
    "preds = np.array([i.tolist() for i in preds])\n",
    "# preds[np.where(preds < 0.5)] = 0\n",
    "# preds[np.where(preds >= 0.5)] = 1\n",
    "print(precision_recall_fscore_support(reals, preds.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2a8a8-ed8e-454b-bf8d-e08fb828c6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec02d4-b1d2-431d-8eb6-666144c31cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5a95a-1cb9-4553-9799-3550959cea67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
