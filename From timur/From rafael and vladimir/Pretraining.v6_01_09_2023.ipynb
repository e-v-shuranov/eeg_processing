{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03477f44-46c2-4a22-aaee-a67878c1816e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:35.919622Z",
     "iopub.status.busy": "2023-09-01T14:45:35.918898Z",
     "iopub.status.idle": "2023-09-01T14:45:36.081588Z",
     "shell.execute_reply": "2023-09-01T14:45:36.079471Z",
     "shell.execute_reply.started": "2023-09-01T14:45:35.919560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep  1 17:45:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   29C    P8    23W / 350W |   1203MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 30%   29C    P8    23W / 350W |      8MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1362      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    910571      C   ...nda3/envs/meta/bin/python     1195MiB |\n",
      "|    1   N/A  N/A      1362      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e513c8-c521-4ac4-b93c-bea7dbb4eac9",
   "metadata": {},
   "source": [
    "##### %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de61d6ab-33e9-40ef-b448-6686a5a4e0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:37.463416Z",
     "iopub.status.busy": "2023-09-01T14:45:37.462764Z",
     "iopub.status.idle": "2023-09-01T14:45:37.471089Z",
     "shell.execute_reply": "2023-09-01T14:45:37.469282Z",
     "shell.execute_reply.started": "2023-09-01T14:45:37.463357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# os.environ['http_proxy'] = \"http://127.0.0.1:3128\"\n",
    "# os.environ['https_proxy'] = \"http://127.0.0.1:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ab062da-1f4d-4f54-965f-49e519bb897c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:59:11.855766Z",
     "iopub.status.busy": "2023-09-01T14:59:11.855011Z",
     "iopub.status.idle": "2023-09-01T14:59:11.865064Z",
     "shell.execute_reply": "2023-09-01T14:59:11.863210Z",
     "shell.execute_reply.started": "2023-09-01T14:59:11.855704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from typing import Callable\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a029d2ef-c060-410a-9c98-aa48d86c7926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:39.189173Z",
     "iopub.status.busy": "2023-09-01T14:45:39.188676Z",
     "iopub.status.idle": "2023-09-01T14:45:39.260184Z",
     "shell.execute_reply": "2023-09-01T14:45:39.259096Z",
     "shell.execute_reply.started": "2023-09-01T14:45:39.189152Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e1e8bc-99d9-4968-9956-fe13fc4433e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:40.559069Z",
     "iopub.status.busy": "2023-09-01T14:45:40.558618Z",
     "iopub.status.idle": "2023-09-01T14:45:40.806255Z",
     "shell.execute_reply": "2023-09-01T14:45:40.805238Z",
     "shell.execute_reply.started": "2023-09-01T14:45:40.559044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c443a-6995-43ca-ac1d-43cfe5ec376a",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef112d9-8b15-407a-b735-cc584072cc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:41.593758Z",
     "iopub.status.busy": "2023-09-01T14:45:41.593508Z",
     "iopub.status.idle": "2023-09-01T14:45:41.599982Z",
     "shell.execute_reply": "2023-09-01T14:45:41.598322Z",
     "shell.execute_reply.started": "2023-09-01T14:45:41.593737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransposeCustom(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransposeCustom, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.transpose(x, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411dce92-23fd-4258-ab4c-73b9f68f8d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:42.135471Z",
     "iopub.status.busy": "2023-09-01T14:45:42.134799Z",
     "iopub.status.idle": "2023-09-01T14:45:42.142226Z",
     "shell.execute_reply": "2023-09-01T14:45:42.140664Z",
     "shell.execute_reply.started": "2023-09-01T14:45:42.135413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config = BertConfig(is_decoder=True, \n",
    "#                     add_cross_attention=True,\n",
    "#                     ff_layer='conv',\n",
    "#                     conv_kernel=1,\n",
    "#                     conv_kernel_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711ae813-492d-4fe1-89ee-8315cb43617f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:43.497274Z",
     "iopub.status.busy": "2023-09-01T14:45:43.496592Z",
     "iopub.status.idle": "2023-09-01T14:45:43.507623Z",
     "shell.execute_reply": "2023-09-01T14:45:43.506090Z",
     "shell.execute_reply.started": "2023-09-01T14:45:43.497214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _make_span_from_seeds(seeds, span, total=None):\n",
    "    inds = list()\n",
    "    for seed in seeds:\n",
    "        for i in range(seed, seed + span):\n",
    "            if total is not None and i >= total:\n",
    "                break\n",
    "            elif i not in inds:\n",
    "                inds.append(int(i))\n",
    "    return np.array(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d78b6b1-0a91-4706-92ca-f52a791ea753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:43.834790Z",
     "iopub.status.busy": "2023-09-01T14:45:43.833384Z",
     "iopub.status.idle": "2023-09-01T14:45:43.846358Z",
     "shell.execute_reply": "2023-09-01T14:45:43.844542Z",
     "shell.execute_reply.started": "2023-09-01T14:45:43.834730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _make_mask(shape, p, total, span, allow_no_inds=False):\n",
    "    # num_mask_spans = np.sum(np.random.rand(total) < p)\n",
    "    # num_mask_spans = int(p * total)\n",
    "    mask = torch.zeros(shape, requires_grad=False, dtype=torch.bool)\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        mask_seeds = list()\n",
    "        while not allow_no_inds and len(mask_seeds) == 0 and p > 0:\n",
    "            mask_seeds = np.nonzero(np.random.rand(total) < p)[0]\n",
    "\n",
    "        mask[i, _make_span_from_seeds(mask_seeds, span, total=total)] = True\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e79430c-e70e-4e42-8f35-3bbae19c2d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:44.181761Z",
     "iopub.status.busy": "2023-09-01T14:45:44.181062Z",
     "iopub.status.idle": "2023-09-01T14:45:44.198145Z",
     "shell.execute_reply": "2023-09-01T14:45:44.196300Z",
     "shell.execute_reply.started": "2023-09-01T14:45:44.181702Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        position = (position.T - position).T / max_len\n",
    "        self.register_buffer('rel_position', position)\n",
    "        \n",
    "        self.conv = torch.nn.Conv1d(max_len, d_model, 25, padding=25 // 2, groups=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        rel_pos = self.conv(self.rel_position[:x.size(1), :x.size(1)][None])[0].T\n",
    "        print(rel_pos.shape)\n",
    "        x = x + rel_pos\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "922d6021-c2cd-4bf2-849a-65eb936d0f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:56:57.093238Z",
     "iopub.status.busy": "2023-09-01T14:56:57.092837Z",
     "iopub.status.idle": "2023-09-01T14:56:57.101238Z",
     "shell.execute_reply": "2023-09-01T14:56:57.099847Z",
     "shell.execute_reply.started": "2023-09-01T14:56:57.093205Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FP1', 'FP2', 'FZ', 'FCZ', 'CZ', 'PZ', 'O1', 'O2', 'F3', 'F4', 'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n"
     ]
    }
   ],
   "source": [
    "channels = ['Fp1', 'Fp2', 'FZ', 'FCz', 'Cz', 'Pz', 'O1', 'O2', 'F3', 'F4', \n",
    "               'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n",
    "channels = [i.upper() for i in channels]\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ade54a7-ca7a-48c7-bb53-85a0f741d795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:11:22.256889Z",
     "iopub.status.busy": "2023-09-01T16:11:22.256612Z",
     "iopub.status.idle": "2023-09-01T16:11:22.280338Z",
     "shell.execute_reply": "2023-09-01T16:11:22.278483Z",
     "shell.execute_reply.started": "2023-09-01T16:11:22.256869Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGEmbedder(torch.nn.Module):\n",
    "    def __init__(self, num_labels=2, channels=channels):\n",
    "        super(EEGEmbedder, self).__init__()\n",
    "        self.config = BertConfig(is_decoder=False, \n",
    "                    add_cross_attention=False,\n",
    "                    ff_layer='linear',\n",
    "                    hidden_size=512,\n",
    "                    num_attention_heads=8,\n",
    "                    num_hidden_layers=8,\n",
    "                    conv_kernel=1,\n",
    "                    conv_kernel_num=1)\n",
    "        self.channels = channels\n",
    "        self.model = BertEncoder(self.config)\n",
    "        \n",
    "        self.pos_e = PositionalEncoding(512, max_len=6000)\n",
    "        self.ch_embedder = torch.nn.Embedding(22, 512)\n",
    "        self.ch_norm = torch.nn.LayerNorm(512)\n",
    "        \n",
    "        self.input_norm = torch.nn.LayerNorm(2)\n",
    "        self.input_embedder = torch.nn.Sequential(\n",
    "            TransposeCustom(),\n",
    "            torch.nn.Conv1d(21, 32, 5, 2, padding=0),\n",
    "            torch.nn.Conv1d(32, 64, 5, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(64 // 2, 64),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(64, 128, 3, 2, padding=0),\n",
    "            torch.nn.Conv1d(128, 196, 3, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(196 // 2, 196),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(196, 256, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(256, 384, 5, 1, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(384 // 2, 384),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(384, 512, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(512, 512, 1, 1, padding=0),\n",
    "            torch.nn.GroupNorm(512 // 2, 512),\n",
    "            torch.nn.GELU(),\n",
    "            TransposeCustom(),\n",
    "        # torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.output_embedder = torch.nn.Linear(512, 512)\n",
    "        self.transpose = TransposeCustom()\n",
    "        \n",
    "        self.mask_embedding = torch.nn.Parameter(torch.normal(0, 512**(-0.5), size=(512,)),\n",
    "                                                   requires_grad=True)\n",
    "        self.placeholder = torch.nn.Parameter(torch.normal(0, 512**(-0.5), size=(512,)),\n",
    "                                                   requires_grad=True)\n",
    "        # self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
    "        \n",
    "    def forward(self, inputs, attention_mask, ch_vector, clf=False):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        embedding += ch_embedding\n",
    "        \n",
    "        # perform masking\n",
    "        embedding_unmasked = embedding.clone() # keep for loss calculation\n",
    "        mask = _make_mask((embedding.shape[0], embedding.shape[1]), 0.05, embedding.shape[1], 10)\n",
    "        embedding[mask] = self.mask_embedding\n",
    "        \n",
    "        # additional vector for classification tasks later\n",
    "        placeholder = torch.zeros((embedding.shape[0], 1, embedding.shape[2]), device=embedding.device)\n",
    "        placeholder += self.placeholder\n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "    \n",
    "        encoder_output = self.output_embedder(encoder_output)\n",
    "\n",
    "        if clf:\n",
    "            logits = self.classifier(encoder_output[:, 0]) #sequence classification\n",
    "            # logits = self.classifier(encoder_output)  # token classification ?\n",
    "            return logits\n",
    "            \n",
    "        \n",
    "        return encoder_output[:, 1:], embedding_unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cfbf3e0-eb6f-4029-b9c2-d9c2b58fca32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:15.624687Z",
     "iopub.status.busy": "2023-09-01T14:57:15.624002Z",
     "iopub.status.idle": "2023-09-01T14:57:15.633254Z",
     "shell.execute_reply": "2023-09-01T14:57:15.631496Z",
     "shell.execute_reply.started": "2023-09-01T14:57:15.624628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = torch.rand(10, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd27018-6fef-4bc5-a704-b269f8006ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:16.143932Z",
     "iopub.status.busy": "2023-09-01T14:57:16.143268Z",
     "iopub.status.idle": "2023-09-01T14:57:16.654032Z",
     "shell.execute_reply": "2023-09-01T14:57:16.653060Z",
     "shell.execute_reply.started": "2023-09-01T14:57:16.143874Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EEGEmbedder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d97a8d-af04-41e3-9d38-52582f2e26f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77774c12-ce6f-47f6-87fe-9b158fdcfdee",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9d6c08d-49a6-4789-a24f-929cb2bd294a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:21.907321Z",
     "iopub.status.busy": "2023-09-01T14:57:21.907044Z",
     "iopub.status.idle": "2023-09-01T14:57:21.913483Z",
     "shell.execute_reply": "2023-09-01T14:57:21.912497Z",
     "shell.execute_reply.started": "2023-09-01T14:57:21.907301Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _generate_negatives(z):\n",
    "    \"\"\"Generate negative samples to compare each sequence location against\"\"\"\n",
    "    num_negatives = 20\n",
    "    batch_size, feat, full_len = z.shape\n",
    "    z_k = z.permute([0, 2, 1]).reshape(-1, feat)\n",
    "    with torch.no_grad():\n",
    "        # candidates = torch.arange(full_len).unsqueeze(-1).expand(-1, self.num_negatives).flatten()\n",
    "        negative_inds = torch.randint(0, full_len-1, size=(batch_size, full_len * num_negatives))\n",
    "        # From wav2vec 2.0 implementation, I don't understand\n",
    "        # negative_inds[negative_inds >= candidates] += 1\n",
    "\n",
    "        for i in range(1, batch_size):\n",
    "            negative_inds[i] += i * full_len\n",
    "\n",
    "    z_k = z_k[negative_inds.view(-1)].view(batch_size, full_len, num_negatives, feat)\n",
    "    return z_k, negative_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "534e0a28-d364-424b-95ea-ba9aef8969e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:22.261127Z",
     "iopub.status.busy": "2023-09-01T14:57:22.260575Z",
     "iopub.status.idle": "2023-09-01T14:57:22.270140Z",
     "shell.execute_reply": "2023-09-01T14:57:22.268338Z",
     "shell.execute_reply.started": "2023-09-01T14:57:22.261093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _calculate_similarity( z, c, negatives):\n",
    "    c = c[..., :].permute([0, 2, 1]).unsqueeze(-2)\n",
    "    z = z.permute([0, 2, 1]).unsqueeze(-2)\n",
    "\n",
    "    # In case the contextualizer matches exactly, need to avoid divide by zero errors\n",
    "    negative_in_target = (c == negatives).all(-1)\n",
    "    targets = torch.cat([c, negatives], dim=-2)\n",
    "\n",
    "    logits = torch.nn.functional.cosine_similarity(z, targets, dim=-1) / 0.1\n",
    "    if negative_in_target.any():\n",
    "        logits[1:][negative_in_target] = float(\"-inf\")\n",
    "\n",
    "    return logits.view(-1, logits.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9679b5-eb5e-45e8-a042-88c24489b697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9402e789-65af-4b04-a351-620f227531b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:23.714259Z",
     "iopub.status.busy": "2023-09-01T14:57:23.713586Z",
     "iopub.status.idle": "2023-09-01T14:57:23.920682Z",
     "shell.execute_reply": "2023-09-01T14:57:23.919292Z",
     "shell.execute_reply.started": "2023-09-01T14:57:23.714202Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitted_paths = ['/media/hdd/data/TUH_pretrain.filtered_1_40.v2.splited/{}'.format(i) for i in os.listdir('/media/hdd/data/TUH_pretrain.filtered_1_40.v2.splited/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9ad2e2d-c13c-4edd-9c7a-f214938b8ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:03:24.659854Z",
     "iopub.status.busy": "2023-09-01T15:03:24.659101Z",
     "iopub.status.idle": "2023-09-01T15:03:24.774579Z",
     "shell.execute_reply": "2023-09-01T15:03:24.773595Z",
     "shell.execute_reply.started": "2023-09-01T15:03:24.659792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = np.load(np.random.choice(splitted_paths, 1)[0], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30b779bf-9dad-4343-869d-72fcc79d5aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:03:25.266500Z",
     "iopub.status.busy": "2023-09-01T15:03:25.265868Z",
     "iopub.status.idle": "2023-09-01T15:03:25.278838Z",
     "shell.execute_reply": "2023-09-01T15:03:25.277362Z",
     "shell.execute_reply.started": "2023-09-01T15:03:25.266459Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'value': array([[   0.65713718,    6.22375014,   -2.35049422, ...,   -4.32513896,\n",
       "          -8.8586023 ,  -75.841741  ],\n",
       "       [   3.9248925 ,   -1.93198942,   -0.36414977, ...,  -10.57051501,\n",
       "         -11.26989617,  -80.12427948],\n",
       "       [  13.20842022,    8.54899494,   -7.81687195, ...,  -12.12372561,\n",
       "          -8.3497504 , -101.30141157],\n",
       "       ...,\n",
       "       [  10.2121722 ,  -22.1981293 ,    3.22008065, ...,   10.15099348,\n",
       "           6.89829338,   62.93709644],\n",
       "       [  -8.0216191 ,   -6.3894576 ,    1.70582126, ...,    7.95412311,\n",
       "           5.13707041,   49.29516421],\n",
       "       [  -8.14800929,   13.18179313,    3.18337053, ...,   12.20375884,\n",
       "           5.62408687,   29.70799475]]), 'value_pure': array([[-3.18417491e+00, -2.23731819e+00, -1.64056494e+01, ...,\n",
       "        -1.53306558e+01, -2.46521817e+01, -7.58417410e+01],\n",
       "       [-4.54006933e+00, -1.42073995e+01, -1.38684382e+01, ...,\n",
       "        -2.40408149e+01, -2.92322764e+01, -8.01242795e+01],\n",
       "       [ 8.67301720e+00, -1.19453772e+00, -2.23878982e+01, ...,\n",
       "        -2.37713133e+01, -2.46453538e+01, -1.01301412e+02],\n",
       "       ...,\n",
       "       [-1.43230814e+00, -3.76614182e+01, -1.42159737e+01, ...,\n",
       "        -7.36132571e+00, -9.37672320e+00,  6.29370964e+01],\n",
       "       [-1.77514588e+01, -1.80989937e+01, -1.58107806e+01, ...,\n",
       "        -9.95057853e+00, -1.08074915e+01,  4.92951642e+01],\n",
       "       [-1.88541195e+01, -3.97882387e-02, -1.40533552e+01, ...,\n",
       "        -4.63392291e+00, -1.05357438e+01,  2.97079947e+01]]), 'date': 's004_2015_11_05', 'id': '134_00013456', 'ref_type': '01_tcp_ar', 'channels': ['FP1', 'FP2', 'FZ', 'FCZ', 'CZ', 'PZ', 'O1', 'O2', 'F3', 'F4', 'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2', 'EKG1'], 'meta': 'CLINICAL HISTORY: A 30-year-old male presented to Temple on the 4th after 10-minute cardiac arrest. CT scan showed diffuse cerebral edema. History of heroin abuse, but by report tox screen negative.\\nMEDICATIONS: Heparin, vancomycin, Zosyn.\\nINTRODUCTION: A 20-minute digital EEG was performed at bedside in the ICU using standard 10-20 system of electrode placement with one channel of EKG. The record was performed at 1:30 in the afternoon. The patient was intubated and comatose, but with some tremulousness.\\nDESCRIPTION OF THE RECORD: This is a technically challenging EEG with diffuse muscle artifact. Underneath the muscle artifact, there does appear to be a low voltage, continuous pattern with delta and head-rocking artifact. There is little in the way of reactivity or variability noted. The patient underwent a cranial nerve, coma exam during the EEG.\\nHeart rate: 144\\nIMPRESSION: Abnormal EEG due to:\\n\\t•\\tReplacement of normal background with a diffusely slow pattern.\\n\\t•\\tAbsence of reactivity or variability.\\nCLINICAL CORRELATION: This EEG will be the baseline for long-term video EEG monitoring to follow. No seizures were recorded.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4279d9-4838-4748-a7c3-f6a51417dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "354bc4ee-ee88-402e-bea8-881e40f16314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:33.605210Z",
     "iopub.status.busy": "2023-09-01T14:57:33.604480Z",
     "iopub.status.idle": "2023-09-01T14:57:33.615459Z",
     "shell.execute_reply": "2023-09-01T14:57:33.613971Z",
     "shell.execute_reply.started": "2023-09-01T14:57:33.605148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161710"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a413d97-8fc1-47a6-b137-3ac8247cf34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39fbf98e-eee4-4232-b16d-33c35d176f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:57:33.910382Z",
     "iopub.status.busy": "2023-09-01T14:57:33.909714Z",
     "iopub.status.idle": "2023-09-01T14:57:33.922455Z",
     "shell.execute_reply": "2023-09-01T14:57:33.920623Z",
     "shell.execute_reply.started": "2023-09-01T14:57:33.910323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def masking(ts):\n",
    "    start_shift = np.random.choice(range(10))\n",
    "    downsampling = 2\n",
    "    indices = np.random.choice(np.array(list(range(110)))[start_shift::10][::downsampling], 5, replace=False)\n",
    "    masked_idx = []\n",
    "    for i in indices:\n",
    "        masked_idx.extend(range(i, i+10))\n",
    "\n",
    "    masked_idx = np.array(masked_idx)\n",
    "    \n",
    "    # mask = np.ones((6000, 2))\n",
    "    # # desync some masked channels\n",
    "    # ts_masked = ts.copy()\n",
    "    # if np.random.choice([0, 1], p=[0.7, 0.3]):\n",
    "    #     ts_masked[masked_idx, np.random.choice([0, 1])] *= 0\n",
    "    # else:\n",
    "    #     ts_masked[masked_idx] *= 0\n",
    "        \n",
    "    return None, masked_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "003c6229-82b7-4dc3-9d01-5539f3ca1e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:01:28.460277Z",
     "iopub.status.busy": "2023-09-01T15:01:28.459716Z",
     "iopub.status.idle": "2023-09-01T15:01:28.484220Z",
     "shell.execute_reply": "2023-09-01T15:01:28.482360Z",
     "shell.execute_reply.started": "2023-09-01T15:01:28.460231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SelectChannels(sample, channels=channels):\n",
    "    signal = sample['value_pure']\n",
    "    \n",
    "    channels_ids = [i for i, val in enumerate(sample['channels']) if i != 3 and val in channels]\n",
    "    \n",
    "    \n",
    "    # choose 2 random channels\n",
    "    # channels_to_train = np.random.choice(channels_ids, 2, replace=False)\n",
    "    # use all available\n",
    "    channels_to_train = channels_ids\n",
    "    signal = signal[:, channels_to_train]\n",
    "    return signal, channels_to_train\n",
    "\n",
    "def SleepEdf():\n",
    "    sample_ch = sample['channels']\n",
    "    return\n",
    "    \n",
    "\n",
    "\n",
    "class TEST(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, preprocess_montage:Callable=SelectChannels) :\n",
    "        super(TEST, self).__init__()\n",
    "        self.main_path = path\n",
    "        self.paths = path\n",
    "        self.preprocess_montage=preprocess_montage\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        # take 60s of recording with specified shift\n",
    "        key = False\n",
    "        while(key == False):\n",
    "            try:\n",
    "                sample = np.load(path, allow_pickle=True).item()\n",
    "                key = True\n",
    "            except Exception as e:\n",
    "                print(\"Path: {} is broken \".format(path), e)\n",
    "                path = np.random.choice(self.paths, 1)[0]\n",
    "                \n",
    "\n",
    "        signal, channels_to_train = self.preprocess_montage(sample)\n",
    "        real_len = signal.shape[0]\n",
    "\n",
    "        channels_vector = torch.tensor((channels_to_train))\n",
    "\n",
    "        \n",
    "        # remove normalization for now with within channel z-norm\n",
    "        # sample_norm = (sample - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector]) / (tuh_filtered_stat_vals['max_vals_filtered'][channels_vector] - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector] + 1e-6)\n",
    "        sample_norm_mean = signal.mean()\n",
    "        sample_norm_std = np.std(signal)\n",
    "        \n",
    "        signal_norm = (signal - sample_norm_mean) / (sample_norm_std)\n",
    "        \n",
    "        if signal_norm.shape[0] < 6000:\n",
    "            signal_norm = np.pad(signal_norm, ((0, 6000 - signal_norm.shape[0]), (0, 0)))\n",
    "        \n",
    "        attention_mask = torch.ones(6000)\n",
    "        attention_mask[real_len:] = 0\n",
    "        return {'anchor': torch.from_numpy(signal_norm).float(), \n",
    "                # 'label': sample_label, \n",
    "                # 'anchor_masked': torch.from_numpy(sample_masked).float(), \n",
    "                # 'mask': torch.tensor(mask),\n",
    "                'channels': channels_vector,\n",
    "                'attention_mask': attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da834726-54e3-47a5-aee5-5559f2db6274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:41.250230Z",
     "iopub.status.busy": "2023-09-01T15:08:41.249806Z",
     "iopub.status.idle": "2023-09-01T15:08:41.256539Z",
     "shell.execute_reply": "2023-09-01T15:08:41.255466Z",
     "shell.execute_reply.started": "2023-09-01T15:08:41.250201Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TEST(splitted_paths, preprocess_montage=functools.partial(SelectChannels, channels=channels))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cfd4bd0a-a2f1-4c2d-802b-04863b0cd9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:41.731661Z",
     "iopub.status.busy": "2023-09-01T15:08:41.730980Z",
     "iopub.status.idle": "2023-09-01T15:08:41.749055Z",
     "shell.execute_reply": "2023-09-01T15:08:41.747925Z",
     "shell.execute_reply.started": "2023-09-01T15:08:41.731602Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': tensor([[ 0.3678,  0.0749,  0.0408,  ..., -0.0528,  0.1377,  0.0048],\n",
       "         [ 0.3655,  0.0216,  0.0055,  ...,  0.0235,  0.1583,  0.0343],\n",
       "         [ 0.3018, -0.0476,  0.0187,  ..., -0.0155,  0.0765, -0.0356],\n",
       "         ...,\n",
       "         [-0.3121, -0.1127, -0.2664,  ..., -0.3250, -0.4115, -0.3452],\n",
       "         [-0.3218, -0.1485, -0.2783,  ..., -0.2441, -0.4151, -0.2793],\n",
       "         [-0.2981, -0.1423, -0.2441,  ..., -0.1679, -0.3665, -0.2556]]),\n",
       " 'channels': tensor([ 0,  1,  2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20, 21]),\n",
       " 'attention_mask': tensor([1., 1., 1.,  ..., 1., 1., 1.])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__getitem__(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a48eb7-0727-43ea-bedb-cd419ecd6532",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95ba1c89-cf1d-48d6-a6dd-4f8b0432ac95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:42.663113Z",
     "iopub.status.busy": "2023-09-01T15:08:42.661667Z",
     "iopub.status.idle": "2023-09-01T15:08:43.204789Z",
     "shell.execute_reply": "2023-09-01T15:08:43.203181Z",
     "shell.execute_reply.started": "2023-09-01T15:08:42.663051Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EEGEmbedder()\n",
    "model.load_state_dict(torch.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c49688-e680-406f-9de5-2eae316eeb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50e2bc04-d8ab-4095-8081-c6e8d56fd6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:44.935890Z",
     "iopub.status.busy": "2023-09-01T15:08:44.935551Z",
     "iopub.status.idle": "2023-09-01T15:08:44.943594Z",
     "shell.execute_reply": "2023-09-01T15:08:44.942437Z",
     "shell.execute_reply.started": "2023-09-01T15:08:44.935861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class NoamLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, d_model=512):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d_model = d_model\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = max(1, self.last_epoch)\n",
    "        factor = min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # scale = self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # return [base_lr * scale for base_lr in self.base_lrs]\n",
    "        return [base_lr * self.d_model ** (-0.5) * factor for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cd39442-574d-489d-9cae-2886fa7b2e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:45.429652Z",
     "iopub.status.busy": "2023-09-01T15:08:45.428858Z",
     "iopub.status.idle": "2023-09-01T15:08:45.440475Z",
     "shell.execute_reply": "2023-09-01T15:08:45.438651Z",
     "shell.execute_reply.started": "2023-09-01T15:08:45.429597Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cossim = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "def cosloss(anchor, real, negative):\n",
    "    a = torch.exp(cossim(anchor, real)) / 0.1\n",
    "    b = sum([torch.exp(cossim(anchor, negative[:, n])) / 0.1 for n in range(negative.shape[1])]) + 1e-6\n",
    "    return -torch.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e28e456c-e80d-4cf6-ad0b-4c6af1427908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:46.713176Z",
     "iopub.status.busy": "2023-09-01T15:08:46.712509Z",
     "iopub.status.idle": "2023-09-01T15:08:46.730923Z",
     "shell.execute_reply": "2023-09-01T15:08:46.729363Z",
     "shell.execute_reply.started": "2023-09-01T15:08:46.713117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    random.seed(torch_seed + worker_id)\n",
    "    np.random.seed((torch_seed + worker_id) % 2**30)\n",
    "\n",
    "train_dataset = TEST(splitted_paths[:-15000])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "test_dataset = TEST(splitted_paths[-15000:])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a8e8d3c-6a8b-4af5-9d2d-98fb4eaa036c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:08:49.221655Z",
     "iopub.status.busy": "2023-09-01T15:08:49.220910Z",
     "iopub.status.idle": "2023-09-01T15:08:49.493589Z",
     "shell.execute_reply": "2023-09-01T15:08:49.491780Z",
     "shell.execute_reply.started": "2023-09-01T15:08:49.221594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bc0dce6-c149-4043-bf79-d84a337177fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "lr_d = 1\n",
    "acc_size = 8\n",
    "training_epochs1 = 100000 // len(train_loader)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr_d)\n",
    "\n",
    "model_test = torch.nn.DataParallel(model)\n",
    "model_test.to('cuda:0')\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optim, start_factor=1.0, end_factor=0.1, total_iters=training_epochs1*len(train_loader))\n",
    "scheduler = NoamLR(optim, 100000, 512)\n",
    "\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25684f3b-1b46-41f3-ab64-342dd82ffb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2292, 43, 98556)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), training_epochs1, training_epochs1 * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a8ee36c-93ab-408d-9171-951b2d01c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()(batch['anchor'][None], batch['mask'][None], batch['channels'][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301d68b-775a-47a1-a1a9-ff2ff4d20b3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train\t12.755858182907104\n",
      "Loss/train\t12.643582820892334\n",
      "Loss/train\t12.454817771911621\n",
      "Loss/train\t12.185070753097534\n",
      "Loss/train\t11.838916063308716\n",
      "Loss: 1.477887749671936\t\n",
      "Loss/train\t11.409443974494934\n",
      "Loss/train\t10.90146255493164\n",
      "Loss/train\t10.320974111557007\n",
      "Loss/train\t9.67824900150299\n",
      "Loss/train\t8.992188572883606\n",
      "Loss: 1.1207029819488525\t\n",
      "Loss/train\t8.31241750717163\n",
      "Loss/train\t7.99466860294342\n",
      "Loss/train\t7.372100114822388\n",
      "Loss/train\t6.819593012332916\n",
      "Loss/train\t6.336482048034668\n",
      "Loss: 0.7635732293128967\t\n",
      "Loss/train\t5.912988305091858\n",
      "Loss/train\t5.541968882083893\n",
      "Loss/train\t5.225658714771271\n",
      "Loss/train\t4.952653110027313\n",
      "Loss/train\t4.719955623149872\n",
      "Loss: 0.576254665851593\t\n",
      "Loss/train\t4.516627132892609\n",
      "Loss/train\t4.346154153347015\n",
      "Loss/train\t4.199998915195465\n",
      "Loss/train\t4.136499226093292\n",
      "Loss/train\t4.017586529254913\n",
      "Loss/train\t3.9136194586753845\n",
      "Loss: 0.48888149857521057\t\n",
      "Loss/train\t3.8248919248580933\n",
      "Loss/train\t3.7474300265312195\n",
      "Loss/train\t3.6797587275505066\n",
      "Loss/train\t3.6180025935173035\n",
      "Loss/train\t3.5654504001140594\n",
      "Loss: 0.4454231560230255\t\n",
      "Loss/train\t3.517749160528183\n",
      "Loss/train\t3.477570593357086\n",
      "Loss/train\t3.4391528964042664\n",
      "Loss/train\t3.4062837064266205\n",
      "Loss/train\t3.3921675980091095\n",
      "Loss: 0.42217832803726196\t\n",
      "Loss/train\t3.365108996629715\n",
      "Loss/train\t3.339961439371109\n",
      "Loss/train\t3.319022983312607\n",
      "Loss/train\t3.299046367406845\n",
      "Loss/train\t3.2820617258548737\n",
      "Loss: 0.4091930687427521\t\n",
      "Loss/train\t3.2660966515541077\n",
      "Loss/train\t3.2521539628505707\n",
      "Loss/train\t3.238929182291031\n",
      "Loss/train\t3.2268972992897034\n",
      "Loss/train\t3.216195225715637\n",
      "Loss: 0.40142062306404114\t\n",
      "Loss/train\t3.2061351239681244\n",
      "Loss/train\t3.1923994719982147\n",
      "Loss/train\t3.1846416890621185\n",
      "Loss/train\t3.1765201687812805\n",
      "Loss/train\t3.1694579124450684\n",
      "Loss: 0.396173357963562\t\n",
      "Loss/train\t3.162583142518997\n",
      "Loss/train\t3.1557197868824005\n",
      "Loss/train\t3.1499793231487274\n",
      "Loss/train\t3.1444895267486572\n",
      "Loss/train\t3.138695240020752\n",
      "Loss: 0.3922988772392273\t\n",
      "Loss/train\t3.1322868168354034\n",
      "Loss/train\t3.1280214488506317\n",
      "Loss/train\t3.1260062754154205\n",
      "Loss/train\t3.1207349598407745\n",
      "Loss/train\t3.1165557503700256\n",
      "Loss: 0.38923749327659607\t\n",
      "Loss/train\t3.111479341983795\n",
      "Loss/train\t3.1068959534168243\n",
      "Loss/train\t3.1029442846775055\n",
      "Loss/train\t3.098528951406479\n",
      "Loss/train\t3.09549817442894\n",
      "Loss: 0.3866656422615051\t\n",
      "Loss/train\t3.092077612876892\n",
      "Loss/train\t3.0873886346817017\n",
      "Loss/train\t3.084429383277893\n",
      "Loss/train\t3.082130581140518\n",
      "Loss/train\t3.0791537761688232\n",
      "Loss/train\t3.075514942407608\n",
      "Loss: 0.38443100452423096\t\n",
      "Loss/train\t3.072321444749832\n",
      "Loss/train\t3.0686399936676025\n",
      "Loss/train\t3.0664722323417664\n",
      "Loss/train\t3.061935842037201\n",
      "Loss/train\t3.0598286986351013\n",
      "Loss: 0.3824310600757599\t\n",
      "Loss/train\t3.0558643341064453\n",
      "Loss/train\t3.0532078444957733\n",
      "Loss/train\t3.050230771303177\n",
      "Loss/train\t3.047433853149414\n",
      "Loss/train\t3.044699102640152\n",
      "Loss: 0.38062915205955505\t\n",
      "Loss/train\t3.043403059244156\n",
      "Loss/train\t3.0398872196674347\n",
      "Loss/train\t3.036885231733322\n",
      "Loss/train\t3.03528892993927\n",
      "Loss/train\t3.032084435224533\n",
      "Loss: 0.37899377942085266\t\n",
      "Loss/train\t3.031604826450348\n",
      "Loss/train\t3.0278061032295227\n",
      "Loss/train\t3.025331050157547\n",
      "Loss/train\t3.022030532360077\n",
      "Loss/train\t3.0207349956035614\n",
      "Loss: 0.37748050689697266\t\n",
      "Loss/train\t3.018094152212143\n",
      "Loss/train\t3.0176146924495697\n",
      "Loss/train\t3.0153778195381165\n",
      "Loss/train\t3.0125092566013336\n",
      "Loss/train\t3.009765535593033\n",
      "Loss/train\t3.0069188475608826\n",
      "Loss: 0.3760727643966675\t\n",
      "Loss/train\t3.006137728691101\n",
      "Loss/train\t3.0043415427207947\n",
      "Loss/train\t3.002405524253845\n",
      "Loss/train\t2.999369651079178\n",
      "Loss/train\t2.9971305429935455\n",
      "Loss: 0.37471261620521545\t\n",
      "Loss/train\t2.994408041238785\n",
      "Loss/train\t2.992760092020035\n",
      "Loss/train\t2.990832597017288\n",
      "Loss/train\t2.990477591753006\n",
      "Loss/train\t2.9877956807613373\n",
      "Loss: 0.3733205795288086\t\n",
      "Loss/train\t2.986118823289871\n",
      "Loss/train\t2.981015980243683\n",
      "Loss/train\t2.9802558720111847\n",
      "Loss/train\t2.9765120148658752\n",
      "Loss/train\t2.9765975773334503\n",
      "Loss: 0.3717987835407257\t\n",
      "Loss/train\t2.9724715650081635\n",
      "Loss/train\t2.9713196754455566\n",
      "Loss/train\t2.967473566532135\n",
      "Loss/train\t2.9643036127090454\n",
      "Loss/train\t2.9623642563819885\n",
      "Loss/train\t2.959965258836746\n",
      "Loss: 0.37001529335975647\t\n",
      "Loss/train\t2.956305652856827\n",
      "Loss/train\t2.9535030126571655\n",
      "Loss/train\t2.950118809938431\n",
      "Loss/train\t2.94686421751976\n",
      "Loss/train\t2.9447926580905914\n",
      "Loss: 0.36811453104019165\t\n",
      "Loss/train\t2.941439241170883\n",
      "Loss/train\t2.940099775791168\n",
      "Loss/train\t2.933786928653717\n",
      "Loss/train\t2.9334504902362823\n",
      "Loss/train\t2.9317177832126617\n",
      "Loss: 0.36634328961372375\t\n",
      "Loss/train\t2.928731918334961\n",
      "Loss/train\t2.925934761762619\n",
      "Loss/train\t2.924750953912735\n",
      "Loss/train\t2.922209084033966\n",
      "Loss/train\t2.918773740530014\n",
      "Loss: 0.36474496126174927\t\n",
      "Loss/train\t2.917858272790909\n",
      "Loss/train\t2.914899706840515\n",
      "Loss/train\t2.912205785512924\n",
      "Loss/train\t2.9107946157455444\n",
      "Loss/train\t2.9089353680610657\n",
      "Loss: 0.3633054494857788\t\n",
      "Loss/train\t2.9032803773880005\n",
      "Loss/train\t2.9044482707977295\n",
      "Loss/train\t2.901307851076126\n",
      "Loss/train\t2.9011556804180145\n",
      "Loss/train\t2.8967393338680267\n",
      "Loss/train\t2.8948283791542053\n",
      "Loss: 0.3619936406612396\t\n",
      "Loss/train\t2.893488496541977\n",
      "Loss/train\t2.8945826292037964\n",
      "Loss/train\t2.890445441007614\n",
      "Loss/train\t2.889322578907013\n",
      "Loss/train\t2.8862860202789307\n",
      "Loss: 0.36085671186447144\t\n",
      "Loss/train\t2.8846550583839417\n",
      "Loss/train\t2.8824138939380646\n",
      "Loss/train\t2.8805632889270782\n",
      "Loss/train\t2.877865046262741\n",
      "Loss: 0.3597930073738098\t\n",
      "Loss/train\t2.876994550228119\n",
      "Loss/train\t2.8748088777065277\n",
      "Loss/train\t2.8739466071128845\n",
      "Loss/train\t2.8730830550193787\n",
      "Loss/train\t2.8697808980941772\n",
      "Loss: 0.35880935192108154\t\n",
      "Loss/train\t2.8698234260082245\n",
      "Loss/train\t2.8656990826129913\n",
      "Loss/train\t2.866015374660492\n",
      "Loss/train\t2.8658622801303864\n",
      "Loss/train\t2.8644455671310425\n",
      "Loss: 0.35783228278160095\t\n",
      "Loss/train\t2.863614559173584\n",
      "Loss/train\t2.8591532707214355\n",
      "Loss/train\t2.856845945119858\n",
      "Loss/train\t2.855754554271698\n",
      "Loss/train\t2.854324847459793\n",
      "Loss: 0.35694777965545654\t\n",
      "Loss/train\t2.8533268868923187\n",
      "Loss/train\t2.854556620121002\n",
      "Loss/train\t2.8517045974731445\n",
      "Loss/train\t2.8503537476062775\n",
      "Loss/train\t2.848848044872284\n",
      "Loss: 0.35607069730758667\t\n",
      "Loss/train\t2.8469757437705994\n",
      "Loss/train\t2.845758020877838\n",
      "Loss/train\t2.8425829708576202\n",
      "Loss/train\t2.8419530391693115\n",
      "Loss: 0.355116069316864\t\n",
      "Loss/train\t2.8403874933719635\n",
      "Loss/train\t2.838493049144745\n",
      "Loss/train\t2.8370776772499084\n",
      "Loss/train\t2.837918758392334\n",
      "Loss/train\t2.832762748003006\n",
      "Loss: 0.35413530468940735\t\n",
      "Loss/train\t2.8325993716716766\n",
      "Loss/train\t2.8309223651885986\n",
      "Loss/train\t2.8307434916496277\n",
      "Loss/train\t2.8266052305698395\n",
      "Loss/train\t2.827120989561081\n",
      "Loss: 0.35319024324417114\t\n",
      "Loss/train\t2.823172479867935\n",
      "Loss/train\t2.824467718601227\n",
      "Loss/train\t2.820710629224777\n",
      "Loss/train\t2.819431245326996\n",
      "Loss/train\t2.8206507861614227\n",
      "Loss: 0.3523656725883484\t\n",
      "Loss/train\t2.819383680820465\n",
      "Loss/train\t2.817619800567627\n",
      "Loss/train\t2.814256966114044\n",
      "Loss/train\t2.814727395772934\n",
      "Loss: 0.3515779972076416\t\n",
      "Loss/train\t2.8120080530643463\n",
      "Loss/train\t2.810046136379242\n",
      "Loss/train\t2.810254007577896\n",
      "Loss/train\t2.8101383447647095\n",
      "Loss/train\t2.8087089359760284\n",
      "Loss: 0.3508453965187073\t\n",
      "Loss/train\t2.8048042356967926\n",
      "Loss/train\t2.8043673634529114\n",
      "Loss/train\t2.8037441074848175\n",
      "Loss/train\t2.8035619258880615\n",
      "Loss/train\t2.8002596497535706\n",
      "Loss: 0.35011374950408936\t\n",
      "Loss/train\t2.8011174499988556\n",
      "Loss/train\t2.8016227781772614\n",
      "Loss/train\t2.7980417907238007\n",
      "Loss/train\t2.79611673951149\n",
      "Loss/train\t2.794576644897461\n",
      "Loss: 0.34943118691444397\t\n",
      "Loss/train\t2.7949137091636658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(training_epochs1):\n",
    "    mean_loss = 0\n",
    "    acc_step = 0\n",
    "    for batch in train_loader:\n",
    "        logits = model_test(\n",
    "            batch['anchor'],#.to('cuda:0'), \n",
    "            None,\n",
    "            batch['channels'].long()\n",
    "            clf=True)\n",
    "        # ae, label = model_test(\n",
    "        #     batch['anchor'],#.to('cuda:0'), \n",
    "        #     None, \n",
    "        #     batch['channels'].long())\n",
    "        \n",
    "        # logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "        fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        mean_loss += loss.item()\n",
    "        acc_step += 1\n",
    "        steps += 1\n",
    "        # raise\n",
    "        if acc_step != 0 and acc_step % acc_size == 0:\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad()\n",
    "            if steps % 100 == 0:\n",
    "                print('Loss/train\\t{}'.format(mean_loss / acc_size))\n",
    "            writer.add_scalar('Loss/train', mean_loss / acc_size, steps)\n",
    "            mean_loss = 0\n",
    "        if steps != 0 and steps % 1000 == 0:\n",
    "            der = 0\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_loader:\n",
    "                        ae, label = model_test(\n",
    "                            batch['anchor'],#.to('cuda:0'), \n",
    "                            None, \n",
    "                            batch['channels'].long())\n",
    "                        logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "                        fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "                        loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "                        loss = loss.mean() / acc_size\n",
    "                        der += loss\n",
    "                der /= len(test_loader)\n",
    "                writer.add_scalar('Loss/test', der, steps)\n",
    "\n",
    "                print('Loss: {}\\t'.format(der))\n",
    "            except:\n",
    "                raise\n",
    "            torch.save(model_test.module.state_dict(), 'models/step.pt'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b119cee-d759-4fd8-a8bf-130e8b8d17d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ee4f4-4764-44d4-b27f-eb1da2804fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ba56e39d-e163-4e2f-a0d4-1825f5921796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:11:25.676018Z",
     "iopub.status.busy": "2023-09-01T16:11:25.675302Z",
     "iopub.status.idle": "2023-09-01T16:11:26.369372Z",
     "shell.execute_reply": "2023-09-01T16:11:26.368477Z",
     "shell.execute_reply.started": "2023-09-01T16:11:25.675956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EEGEmbedder()\n",
    "model.load_state_dict(torch.load('/media/hdd/pretraining/models/step.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d728f769-bff6-4ecf-b750-a3e183a65366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:05:56.594389Z",
     "iopub.status.busy": "2023-09-01T16:05:56.593842Z",
     "iopub.status.idle": "2023-09-01T16:05:56.854542Z",
     "shell.execute_reply": "2023-09-01T16:05:56.852821Z",
     "shell.execute_reply.started": "2023-09-01T16:05:56.594345Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m model2 \u001b[38;5;241m=\u001b[39m ClassifierEEGEmbedder(model)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m sample \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manchor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m       \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[122], line 9\u001b[0m, in \u001b[0;36mClassifierEEGEmbedder.forward\u001b[0;34m(self, inputs, attention_mask, ch_vector)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, attention_mask, ch_vector,):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# x, label= self.pretrained(inputs, attention_mask, ch_vector,)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# x = self.my_new_layers(label)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[94], line 58\u001b[0m, in \u001b[0;36mEEGEmbedder.forward\u001b[0;34m(self, inputs, attention_mask, ch_vector, clf)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, attention_mask, ch_vector, clf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 58\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# create embedding for two channel indexes and sumup them to a single one\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     ch_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mch_embedder(ch_vector)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mTransposeCustom.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "class ClassifierEEGEmbedder(torch.nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(ClassifierEEGEmbedder, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.my_new_layers = torch.nn.Sequential(torch.nn.Linear(self.pretrained.config.hidden_size, self.pretrained.config.num_labels))\n",
    "    \n",
    "    def forward(self, inputs, attention_mask, ch_vector,):\n",
    "        # x, label= self.pretrained(inputs, attention_mask, ch_vector,)\n",
    "        x = self.pretrained(inputs, attention_mask, ch_vector)\n",
    "        \n",
    "        print(x)\n",
    "        # x = self.my_new_layers(label)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "model2 = ClassifierEEGEmbedder(model).to(device)\n",
    "\n",
    "sample = test_dataset.__getitem__(4)\n",
    "\n",
    "model2(sample['anchor'].to(device), \n",
    "       None, \n",
    "       sample['channels'].long().to(device)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1541afaa-f783-4d93-ac55-2639fdebb5c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:58:46.436716Z",
     "iopub.status.busy": "2023-09-01T15:58:46.435986Z",
     "iopub.status.idle": "2023-09-01T15:58:46.449947Z",
     "shell.execute_reply": "2023-09-01T15:58:46.447731Z",
     "shell.execute_reply.started": "2023-09-01T15:58:46.436655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 21])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['anchor'].to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bb1462e6-0df1-444f-8047-1b34d47caacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:41:18.164302Z",
     "iopub.status.busy": "2023-09-01T15:41:18.163560Z",
     "iopub.status.idle": "2023-09-01T15:41:18.179669Z",
     "shell.execute_reply": "2023-09-01T15:41:18.177901Z",
     "shell.execute_reply.started": "2023-09-01T15:41:18.164240Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': tensor([[-2.0693e+00, -1.4693e+00, -9.1560e-03,  ..., -4.1035e+00,\n",
       "          -3.9363e+00, -4.0551e+00],\n",
       "         [-2.0585e+00, -1.4897e+00,  6.2453e-04,  ..., -4.0526e+00,\n",
       "          -3.8592e+00, -4.0669e+00],\n",
       "         [-1.8462e+00, -1.3069e+00,  2.4727e-01,  ..., -3.9245e+00,\n",
       "          -3.7516e+00, -3.8181e+00],\n",
       "         ...,\n",
       "         [-4.8936e-01, -5.6444e-01, -5.1781e-01,  ...,  4.8580e-01,\n",
       "           3.1735e-01,  7.0941e-01],\n",
       "         [-9.7947e-02, -9.8642e-02, -1.3797e-01,  ...,  9.3987e-01,\n",
       "           7.8519e-01,  1.2159e+00],\n",
       "         [-1.8030e-01, -1.2938e-01, -1.6457e-01,  ...,  7.5456e-01,\n",
       "           5.9439e-01,  1.1224e+00]]),\n",
       " 'channels': tensor([ 0,  1,  2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20, 21]),\n",
       " 'attention_mask': tensor([1., 1., 1.,  ..., 1., 1., 1.])}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14cbc066-cabc-40b2-845a-139ba75b3308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T15:40:30.181967Z",
     "iopub.status.busy": "2023-09-01T15:40:30.181493Z",
     "iopub.status.idle": "2023-09-01T15:40:30.192761Z",
     "shell.execute_reply": "2023-09-01T15:40:30.190915Z",
     "shell.execute_reply.started": "2023-09-01T15:40:30.181930Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGClassificator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGClassificator, self).__init__()\n",
    "\n",
    "        self.EEGEmbedder_model = EEGEmbedder()\n",
    "        # self.EEGEmbedder_model = torch.load('/home/evgeniy/eeg_processing/models/model_v1.npy')\n",
    "        # self.EEGEmbedder_model = torch.load('/home/evgeniy/models/EEGEmbeder_TUH_Bert_from_Timur_25_08_2023/step.pt')\n",
    "        # self.EEGEmbedder_model.load_state_dict(torch.load('/home/evgeniy/models/EEGEmbeder_TUH_Bert_from_Timur_25_08_2023/step_25epochs.pt'))\n",
    "        self.EEGEmbedder_model.load_state_dict(torch.load('/media/hdd/evgeniy/eeg_models/step_25epochs.pt'))\n",
    "        self.EEGEmbedder_model.eval()\n",
    "\n",
    "        # model = TheModelClass(*args, **kwargs)\n",
    "        # model.load_state_dict(torch.load(PATH))\n",
    "        # model.eval()\n",
    "\n",
    "        self.classification = torch.nn.Sequential(\n",
    "            # torch.nn.Linear(768, 256),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.Linear(256, 2),\n",
    "            # torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs, attention_mask, ch_vector,placeholder):\n",
    "        EEGembedding, label = self.EEGEmbedder_model(inputs, attention_mask, ch_vector)\n",
    "        pred = self.classification(label)\n",
    "        return pred, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0300b-9b95-4741-961f-f3b471ad7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "       # self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "    def forward(self, inputs, attention_mask, ch_vector, clf=False):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        embedding += ch_embedding\n",
    "        \n",
    "        # perform masking\n",
    "        embedding_unmasked = embedding.clone() # keep for loss calculation\n",
    "        mask = _make_mask((embedding.shape[0], embedding.shape[1]), 0.05, embedding.shape[1], 10)\n",
    "        embedding[mask] = self.mask_embedding\n",
    "        \n",
    "        # additional vector for classification tasks later\n",
    "        placeholder = torch.zeros((embedding.shape[0], 1, embedding.shape[2]), device=embedding.device)\n",
    "        placeholder += self.placeholder\n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "    \n",
    "        encoder_output = self.output_embedder(encoder_output)\n",
    "\n",
    "        if clf:\n",
    "            logits = self.classifier(encoder_output[:, 0]) #sequence classification\n",
    "            # logits = self.classifier(encoder_output)  # token classification ?\n",
    "            return logits\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
