{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090ef1a-2d52-46b2-ba9e-cd2c6a07170f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03477f44-46c2-4a22-aaee-a67878c1816e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T17:04:35.911679Z",
     "iopub.status.busy": "2023-09-01T17:04:35.911103Z",
     "iopub.status.idle": "2023-09-01T17:04:36.633199Z",
     "shell.execute_reply": "2023-09-01T17:04:36.631259Z",
     "shell.execute_reply.started": "2023-09-01T17:04:35.911630Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep  1 20:04:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8    21W / 350W |   4257MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 34%   45C    P2   114W / 350W |   1717MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1362      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    910571      C   ...nda3/envs/meta/bin/python     1195MiB |\n",
      "|    0   N/A  N/A   1063255      C   /usr/bin/python3                 2033MiB |\n",
      "|    0   N/A  N/A   1064974      C   ...da3/envs/meta/bin/python3     1021MiB |\n",
      "|    1   N/A  N/A      1362      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   1064974      C   ...da3/envs/meta/bin/python3     1709MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "# !export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e513c8-c521-4ac4-b93c-bea7dbb4eac9",
   "metadata": {},
   "source": [
    "##### %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de61d6ab-33e9-40ef-b448-6686a5a4e0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:31.178335Z",
     "iopub.status.busy": "2023-09-01T16:57:31.177692Z",
     "iopub.status.idle": "2023-09-01T16:57:31.186610Z",
     "shell.execute_reply": "2023-09-01T16:57:31.185009Z",
     "shell.execute_reply.started": "2023-09-01T16:57:31.178274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# os.environ['http_proxy'] = \"http://127.0.0.1:3128\"\n",
    "# os.environ['https_proxy'] = \"http://127.0.0.1:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ab062da-1f4d-4f54-965f-49e519bb897c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T11:53:01.322093Z",
     "iopub.status.busy": "2023-09-05T11:53:01.321411Z",
     "iopub.status.idle": "2023-09-05T11:53:01.331516Z",
     "shell.execute_reply": "2023-09-05T11:53:01.329672Z",
     "shell.execute_reply.started": "2023-09-05T11:53:01.322036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from typing import Callable\n",
    "import functools\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a029d2ef-c060-410a-9c98-aa48d86c7926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.473936Z",
     "iopub.status.busy": "2023-09-01T16:57:32.473677Z",
     "iopub.status.idle": "2023-09-01T16:57:32.524432Z",
     "shell.execute_reply": "2023-09-01T16:57:32.523458Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.473918Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e1e8bc-99d9-4968-9956-fe13fc4433e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.525333Z",
     "iopub.status.busy": "2023-09-01T16:57:32.525108Z",
     "iopub.status.idle": "2023-09-01T16:57:32.710473Z",
     "shell.execute_reply": "2023-09-01T16:57:32.709524Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.525316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c443a-6995-43ca-ac1d-43cfe5ec376a",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef112d9-8b15-407a-b735-cc584072cc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.711429Z",
     "iopub.status.busy": "2023-09-01T16:57:32.711253Z",
     "iopub.status.idle": "2023-09-01T16:57:32.716109Z",
     "shell.execute_reply": "2023-09-01T16:57:32.715273Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.711414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransposeCustom(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransposeCustom, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.transpose(x, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411dce92-23fd-4258-ab4c-73b9f68f8d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.718072Z",
     "iopub.status.busy": "2023-09-01T16:57:32.717904Z",
     "iopub.status.idle": "2023-09-01T16:57:32.749452Z",
     "shell.execute_reply": "2023-09-01T16:57:32.748584Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.718057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config = BertConfig(is_decoder=True, \n",
    "#                     add_cross_attention=True,\n",
    "#                     ff_layer='conv',\n",
    "#                     conv_kernel=1,\n",
    "#                     conv_kernel_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d78b6b1-0a91-4706-92ca-f52a791ea753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.776768Z",
     "iopub.status.busy": "2023-09-01T16:57:32.776522Z",
     "iopub.status.idle": "2023-09-01T16:57:32.807484Z",
     "shell.execute_reply": "2023-09-01T16:57:32.806234Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.776746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _make_span_from_seeds(seeds, span, total=None):\n",
    "    inds = list()\n",
    "    for seed in seeds:\n",
    "        for i in range(seed, seed + span):\n",
    "            if total is not None and i >= total:\n",
    "                break\n",
    "            elif i not in inds:\n",
    "                inds.append(int(i))\n",
    "    return np.array(inds)\n",
    "\n",
    "def _make_mask(shape, p, total, span, allow_no_inds=False):\n",
    "    # num_mask_spans = np.sum(np.random.rand(total) < p)\n",
    "    # num_mask_spans = int(p * total)\n",
    "    mask = torch.zeros(shape, requires_grad=False, dtype=torch.bool)\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        mask_seeds = list()\n",
    "        while not allow_no_inds and len(mask_seeds) == 0 and p > 0:\n",
    "            mask_seeds = np.nonzero(np.random.rand(total) < p)[0]\n",
    "\n",
    "        mask[i, _make_span_from_seeds(mask_seeds, span, total=total)] = True\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e79430c-e70e-4e42-8f35-3bbae19c2d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.809402Z",
     "iopub.status.busy": "2023-09-01T16:57:32.808998Z",
     "iopub.status.idle": "2023-09-01T16:57:32.834710Z",
     "shell.execute_reply": "2023-09-01T16:57:32.832987Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.809366Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        position = (position.T - position).T / max_len\n",
    "        self.register_buffer('rel_position', position)\n",
    "        \n",
    "        self.conv = torch.nn.Conv1d(max_len, d_model, 25, padding=25 // 2, groups=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        rel_pos = self.conv(self.rel_position[:x.size(1), :x.size(1)][None])[0].T\n",
    "        print(rel_pos.shape)\n",
    "        x = x + rel_pos\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922d6021-c2cd-4bf2-849a-65eb936d0f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.837919Z",
     "iopub.status.busy": "2023-09-01T16:57:32.836564Z",
     "iopub.status.idle": "2023-09-01T16:57:32.862063Z",
     "shell.execute_reply": "2023-09-01T16:57:32.860295Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.837866Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FP1', 'FP2', 'FZ', 'FCZ', 'CZ', 'PZ', 'O1', 'O2', 'F3', 'F4', 'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n"
     ]
    }
   ],
   "source": [
    "channels = ['Fp1', 'Fp2', 'FZ', 'FCz', 'Cz', 'Pz', 'O1', 'O2', 'F3', 'F4', \n",
    "               'F7', 'F8', 'C3', 'C4', 'T3', 'T4', 'P3', 'P4', 'T5', 'T6', 'A1', 'A2']\n",
    "channels = [i.upper() for i in channels]\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3ade54a7-ca7a-48c7-bb53-85a0f741d795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T11:27:41.049644Z",
     "iopub.status.busy": "2023-09-07T11:27:41.048866Z",
     "iopub.status.idle": "2023-09-07T11:27:41.089640Z",
     "shell.execute_reply": "2023-09-07T11:27:41.087769Z",
     "shell.execute_reply.started": "2023-09-07T11:27:41.049578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGEmbedder(torch.nn.Module):\n",
    "    def __init__(self, num_labels=2, channels=channels):\n",
    "        super(EEGEmbedder, self).__init__()\n",
    "        self.config = BertConfig(is_decoder=False, \n",
    "                    add_cross_attention=False,\n",
    "                    ff_layer='linear',\n",
    "                    hidden_size=512,\n",
    "                    num_attention_heads=8,\n",
    "                    num_hidden_layers=8,\n",
    "                    conv_kernel=1,\n",
    "                    conv_kernel_num=1)\n",
    "        self.channels = channels\n",
    "        self.model = BertEncoder(self.config)\n",
    "\n",
    "        self.clf = True\n",
    "        self.masking = True\n",
    "        \n",
    "        \n",
    "        self.pos_e = PositionalEncoding(512, max_len=6000)\n",
    "        self.ch_embedder = torch.nn.Embedding(22, 512)\n",
    "        self.ch_norm = torch.nn.LayerNorm(512)\n",
    "        \n",
    "        self.input_norm = torch.nn.LayerNorm(2)\n",
    "        self.input_embedder = torch.nn.Sequential(\n",
    "            TransposeCustom(),\n",
    "            torch.nn.Conv1d(21, 32, 5, 2, padding=0),\n",
    "            torch.nn.Conv1d(32, 64, 5, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(64 // 2, 64),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(64, 128, 3, 2, padding=0),\n",
    "            torch.nn.Conv1d(128, 196, 3, 2, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(196 // 2, 196),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(196, 256, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(256, 384, 5, 1, padding=0),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.GroupNorm(384 // 2, 384),\n",
    "            torch.nn.GELU(),\n",
    "            # TransposeCustom(),\n",
    "            torch.nn.Conv1d(384, 512, 5, 1, padding=0),\n",
    "            torch.nn.Conv1d(512, 512, 1, 1, padding=0),\n",
    "            torch.nn.GroupNorm(512 // 2, 512),\n",
    "            torch.nn.GELU(),\n",
    "            TransposeCustom(),\n",
    "        # torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.output_embedder = torch.nn.Linear(512, 512)\n",
    "        self.transpose = TransposeCustom()\n",
    "        \n",
    "        self.mask_embedding = torch.nn.Parameter(torch.normal(0, 512**(-0.5), size=(512,)),\n",
    "                                                   requires_grad=True)\n",
    "        self.placeholder = torch.nn.Parameter(torch.normal(0, 512**(-0.5), size=(512,)),\n",
    "                                                   requires_grad=True)\n",
    "        # self.classifier = torch.nn.Linear()\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.Linear(768, 256),\n",
    "            torch.nn.Linear(self.config.hidden_size, self.config.num_labels),\n",
    "            torch.nn.Linear(256, 2),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs, attention_mask, ch_vector):\n",
    "        embedding = self.input_embedder(inputs)\n",
    "        # create embedding for two channel indexes and sumup them to a single one\n",
    "        ch_embedding = self.ch_embedder(ch_vector).sum(1)\n",
    "        ch_embedding = ch_embedding[:, None]\n",
    "        embedding += ch_embedding\n",
    "        embedding_unmasked = embedding.clone() # keep for loss calculation\n",
    "        # perform masking\n",
    "        if self.masking:\n",
    "            mask = _make_mask((embedding.shape[0], embedding.shape[1]), 0.05, embedding.shape[1], 10)\n",
    "            embedding[mask] = self.mask_embedding\n",
    "        \n",
    "        # additional vector for classification tasks later\n",
    "        placeholder = torch.zeros((embedding.shape[0], 1, embedding.shape[2]), device=embedding.device)\n",
    "        placeholder += self.placeholder\n",
    "        embedding = torch.cat([placeholder, embedding], 1)\n",
    "        encoder_output = self.model(embedding, output_hidden_states=True,\n",
    "                               output_attentions=True)[0]\n",
    "    \n",
    "        encoder_output = self.output_embedder(encoder_output)\n",
    "\n",
    "        if self.clf:\n",
    "            logits = self.classifier(encoder_output[:, 0]) #sequence classification\n",
    "            # logits = self.classifier(encoder_output)  # token classification ?\n",
    "            return logits\n",
    "            \n",
    "        \n",
    "        return encoder_output[:, 1:], embedding_unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cfbf3e0-eb6f-4029-b9c2-d9c2b58fca32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.902506Z",
     "iopub.status.busy": "2023-09-01T16:57:32.901233Z",
     "iopub.status.idle": "2023-09-01T16:57:32.936643Z",
     "shell.execute_reply": "2023-09-01T16:57:32.934899Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.902455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = torch.rand(10, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd27018-6fef-4bc5-a704-b269f8006ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:32.939789Z",
     "iopub.status.busy": "2023-09-01T16:57:32.938540Z",
     "iopub.status.idle": "2023-09-01T16:57:33.372964Z",
     "shell.execute_reply": "2023-09-01T16:57:33.372097Z",
     "shell.execute_reply.started": "2023-09-01T16:57:32.939736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EEGEmbedder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d97a8d-af04-41e3-9d38-52582f2e26f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77774c12-ce6f-47f6-87fe-9b158fdcfdee",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d6c08d-49a6-4789-a24f-929cb2bd294a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.374040Z",
     "iopub.status.busy": "2023-09-01T16:57:33.373847Z",
     "iopub.status.idle": "2023-09-01T16:57:33.379198Z",
     "shell.execute_reply": "2023-09-01T16:57:33.378435Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.374025Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _generate_negatives(z):\n",
    "    \"\"\"Generate negative samples to compare each sequence location against\"\"\"\n",
    "    num_negatives = 20\n",
    "    batch_size, feat, full_len = z.shape\n",
    "    z_k = z.permute([0, 2, 1]).reshape(-1, feat)\n",
    "    with torch.no_grad():\n",
    "        # candidates = torch.arange(full_len).unsqueeze(-1).expand(-1, self.num_negatives).flatten()\n",
    "        negative_inds = torch.randint(0, full_len-1, size=(batch_size, full_len * num_negatives))\n",
    "        # From wav2vec 2.0 implementation, I don't understand\n",
    "        # negative_inds[negative_inds >= candidates] += 1\n",
    "\n",
    "        for i in range(1, batch_size):\n",
    "            negative_inds[i] += i * full_len\n",
    "\n",
    "    z_k = z_k[negative_inds.view(-1)].view(batch_size, full_len, num_negatives, feat)\n",
    "    return z_k, negative_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "534e0a28-d364-424b-95ea-ba9aef8969e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.379928Z",
     "iopub.status.busy": "2023-09-01T16:57:33.379776Z",
     "iopub.status.idle": "2023-09-01T16:57:33.418432Z",
     "shell.execute_reply": "2023-09-01T16:57:33.417600Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.379914Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _calculate_similarity( z, c, negatives):\n",
    "    c = c[..., :].permute([0, 2, 1]).unsqueeze(-2)\n",
    "    z = z.permute([0, 2, 1]).unsqueeze(-2)\n",
    "\n",
    "    # In case the contextualizer matches exactly, need to avoid divide by zero errors\n",
    "    negative_in_target = (c == negatives).all(-1)\n",
    "    targets = torch.cat([c, negatives], dim=-2)\n",
    "\n",
    "    logits = torch.nn.functional.cosine_similarity(z, targets, dim=-1) / 0.1\n",
    "    if negative_in_target.any():\n",
    "        logits[1:][negative_in_target] = float(\"-inf\")\n",
    "\n",
    "    return logits.view(-1, logits.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9679b5-eb5e-45e8-a042-88c24489b697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9402e789-65af-4b04-a351-620f227531b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.419167Z",
     "iopub.status.busy": "2023-09-01T16:57:33.419015Z",
     "iopub.status.idle": "2023-09-01T16:57:33.533724Z",
     "shell.execute_reply": "2023-09-01T16:57:33.532804Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.419154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitted_paths = ['/media/hdd/data/TUH_pretrain.filtered_1_40.v2.splited/{}'.format(i) for i in os.listdir('/media/hdd/data/TUH_pretrain.filtered_1_40.v2.splited/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ad2e2d-c13c-4edd-9c7a-f214938b8ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.534567Z",
     "iopub.status.busy": "2023-09-01T16:57:33.534403Z",
     "iopub.status.idle": "2023-09-01T16:57:33.594397Z",
     "shell.execute_reply": "2023-09-01T16:57:33.593261Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.534553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = np.load(np.random.choice(splitted_paths, 1)[0], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4279d9-4838-4748-a7c3-f6a51417dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "354bc4ee-ee88-402e-bea8-881e40f16314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.595111Z",
     "iopub.status.busy": "2023-09-01T16:57:33.594939Z",
     "iopub.status.idle": "2023-09-01T16:57:33.602478Z",
     "shell.execute_reply": "2023-09-01T16:57:33.601669Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.595096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161710"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a413d97-8fc1-47a6-b137-3ac8247cf34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39fbf98e-eee4-4232-b16d-33c35d176f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.603177Z",
     "iopub.status.busy": "2023-09-01T16:57:33.603024Z",
     "iopub.status.idle": "2023-09-01T16:57:33.627233Z",
     "shell.execute_reply": "2023-09-01T16:57:33.626168Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.603163Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def masking(ts):\n",
    "    start_shift = np.random.choice(range(10))\n",
    "    downsampling = 2\n",
    "    indices = np.random.choice(np.array(list(range(110)))[start_shift::10][::downsampling], 5, replace=False)\n",
    "    masked_idx = []\n",
    "    for i in indices:\n",
    "        masked_idx.extend(range(i, i+10))\n",
    "\n",
    "    masked_idx = np.array(masked_idx)\n",
    "    \n",
    "    # mask = np.ones((6000, 2))\n",
    "    # # desync some masked channels\n",
    "    # ts_masked = ts.copy()\n",
    "    # if np.random.choice([0, 1], p=[0.7, 0.3]):\n",
    "    #     ts_masked[masked_idx, np.random.choice([0, 1])] *= 0\n",
    "    # else:\n",
    "    #     ts_masked[masked_idx] *= 0\n",
    "        \n",
    "    return None, masked_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003c6229-82b7-4dc3-9d01-5539f3ca1e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.628440Z",
     "iopub.status.busy": "2023-09-01T16:57:33.628223Z",
     "iopub.status.idle": "2023-09-01T16:57:33.659490Z",
     "shell.execute_reply": "2023-09-01T16:57:33.657896Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.628421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SelectChannels(sample, channels=channels):\n",
    "    signal = sample['value_pure']\n",
    "    \n",
    "    channels_ids = [i for i, val in enumerate(sample['channels']) if i != 3 and val in channels]\n",
    "    \n",
    "    \n",
    "    # choose 2 random channels\n",
    "    # channels_to_train = np.random.choice(channels_ids, 2, replace=False)\n",
    "    # use all available\n",
    "    channels_to_train = channels_ids\n",
    "    signal = signal[:, channels_to_train]\n",
    "    return signal, channels_to_train\n",
    "\n",
    "def SleepEdf():\n",
    "    sample_ch = sample['channels']\n",
    "    return\n",
    "    \n",
    "\n",
    "\n",
    "class TEST(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, preprocess_montage:Callable=SelectChannels) :\n",
    "        super(TEST, self).__init__()\n",
    "        self.main_path = path\n",
    "        self.paths = path\n",
    "        self.preprocess_montage=preprocess_montage\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        # take 60s of recording with specified shift\n",
    "        key = False\n",
    "        while(key == False):\n",
    "            try:\n",
    "                sample = np.load(path, allow_pickle=True).item()\n",
    "                key = True\n",
    "            except Exception as e:\n",
    "                print(\"Path: {} is broken \".format(path), e)\n",
    "                path = np.random.choice(self.paths, 1)[0]\n",
    "                \n",
    "\n",
    "        signal, channels_to_train = self.preprocess_montage(sample)\n",
    "        real_len = signal.shape[0]\n",
    "\n",
    "        channels_vector = torch.tensor((channels_to_train))\n",
    "\n",
    "        \n",
    "        # remove normalization for now with within channel z-norm\n",
    "        # sample_norm = (sample - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector]) / (tuh_filtered_stat_vals['max_vals_filtered'][channels_vector] - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector] + 1e-6)\n",
    "        sample_norm_mean = signal.mean()\n",
    "        sample_norm_std = np.std(signal)\n",
    "        \n",
    "        signal_norm = (signal - sample_norm_mean) / (sample_norm_std)\n",
    "        \n",
    "        if signal_norm.shape[0] < 6000:\n",
    "            signal_norm = np.pad(signal_norm, ((0, 6000 - signal_norm.shape[0]), (0, 0)))\n",
    "        \n",
    "        attention_mask = torch.ones(6000)\n",
    "        attention_mask[real_len:] = 0\n",
    "        return {'anchor': torch.from_numpy(signal_norm).float(), \n",
    "                # 'label': sample_label, \n",
    "                # 'anchor_masked': torch.from_numpy(sample_masked).float(), \n",
    "                # 'mask': torch.tensor(mask),\n",
    "                'channels': channels_vector,\n",
    "                'attention_mask': attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da834726-54e3-47a5-aee5-5559f2db6274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.664705Z",
     "iopub.status.busy": "2023-09-01T16:57:33.664389Z",
     "iopub.status.idle": "2023-09-01T16:57:33.690379Z",
     "shell.execute_reply": "2023-09-01T16:57:33.689205Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.664678Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TEST(splitted_paths, preprocess_montage=functools.partial(SelectChannels, channels=channels))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfd4bd0a-a2f1-4c2d-802b-04863b0cd9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T11:59:44.142522Z",
     "iopub.status.busy": "2023-09-05T11:59:44.141965Z",
     "iopub.status.idle": "2023-09-05T11:59:44.152521Z",
     "shell.execute_reply": "2023-09-05T11:59:44.151634Z",
     "shell.execute_reply.started": "2023-09-05T11:59:44.142490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': tensor([[-2.0693e+00, -1.4693e+00, -9.1560e-03,  ..., -4.1035e+00,\n",
       "          -3.9363e+00, -4.0551e+00],\n",
       "         [-2.0585e+00, -1.4897e+00,  6.2453e-04,  ..., -4.0526e+00,\n",
       "          -3.8592e+00, -4.0669e+00],\n",
       "         [-1.8462e+00, -1.3069e+00,  2.4727e-01,  ..., -3.9245e+00,\n",
       "          -3.7516e+00, -3.8181e+00],\n",
       "         ...,\n",
       "         [-4.8936e-01, -5.6444e-01, -5.1781e-01,  ...,  4.8580e-01,\n",
       "           3.1735e-01,  7.0941e-01],\n",
       "         [-9.7947e-02, -9.8642e-02, -1.3797e-01,  ...,  9.3987e-01,\n",
       "           7.8519e-01,  1.2159e+00],\n",
       "         [-1.8030e-01, -1.2938e-01, -1.6457e-01,  ...,  7.5456e-01,\n",
       "           5.9439e-01,  1.1224e+00]]),\n",
       " 'channels': tensor([ 0,  1,  2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20, 21]),\n",
       " 'attention_mask': tensor([1., 1., 1.,  ..., 1., 1., 1.])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__getitem__(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a48eb7-0727-43ea-bedb-cd419ecd6532",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95ba1c89-cf1d-48d6-a6dd-4f8b0432ac95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:33.726932Z",
     "iopub.status.busy": "2023-09-01T16:57:33.726769Z",
     "iopub.status.idle": "2023-09-01T16:57:34.084284Z",
     "shell.execute_reply": "2023-09-01T16:57:34.083125Z",
     "shell.execute_reply.started": "2023-09-01T16:57:33.726918Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EEGEmbedder()\n",
    "# model.load_state_dict(torch.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c49688-e680-406f-9de5-2eae316eeb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50e2bc04-d8ab-4095-8081-c6e8d56fd6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:34.085256Z",
     "iopub.status.busy": "2023-09-01T16:57:34.085081Z",
     "iopub.status.idle": "2023-09-01T16:57:34.090883Z",
     "shell.execute_reply": "2023-09-01T16:57:34.090036Z",
     "shell.execute_reply.started": "2023-09-01T16:57:34.085241Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class NoamLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, d_model=512):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d_model = d_model\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = max(1, self.last_epoch)\n",
    "        factor = min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # scale = self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        # return [base_lr * scale for base_lr in self.base_lrs]\n",
    "        return [base_lr * self.d_model ** (-0.5) * factor for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd39442-574d-489d-9cae-2886fa7b2e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:34.091622Z",
     "iopub.status.busy": "2023-09-01T16:57:34.091469Z",
     "iopub.status.idle": "2023-09-01T16:57:34.130087Z",
     "shell.execute_reply": "2023-09-01T16:57:34.129312Z",
     "shell.execute_reply.started": "2023-09-01T16:57:34.091608Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cossim = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "def cosloss(anchor, real, negative):\n",
    "    a = torch.exp(cossim(anchor, real)) / 0.1\n",
    "    b = sum([torch.exp(cossim(anchor, negative[:, n])) / 0.1 for n in range(negative.shape[1])]) + 1e-6\n",
    "    return -torch.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e28e456c-e80d-4cf6-ad0b-4c6af1427908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:34.130671Z",
     "iopub.status.busy": "2023-09-01T16:57:34.130520Z",
     "iopub.status.idle": "2023-09-01T16:57:34.157038Z",
     "shell.execute_reply": "2023-09-01T16:57:34.155976Z",
     "shell.execute_reply.started": "2023-09-01T16:57:34.130658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    random.seed(torch_seed + worker_id)\n",
    "    np.random.seed((torch_seed + worker_id) % 2**30)\n",
    "\n",
    "train_dataset = TEST(splitted_paths[:-15000])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "test_dataset = TEST(splitted_paths[-15000:])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a8e8d3c-6a8b-4af5-9d2d-98fb4eaa036c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:34.158087Z",
     "iopub.status.busy": "2023-09-01T16:57:34.157853Z",
     "iopub.status.idle": "2023-09-01T16:57:34.183509Z",
     "shell.execute_reply": "2023-09-01T16:57:34.181889Z",
     "shell.execute_reply.started": "2023-09-01T16:57:34.158066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bc0dce6-c149-4043-bf79-d84a337177fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:34.185082Z",
     "iopub.status.busy": "2023-09-01T16:57:34.184676Z",
     "iopub.status.idle": "2023-09-01T16:57:35.483609Z",
     "shell.execute_reply": "2023-09-01T16:57:35.482292Z",
     "shell.execute_reply.started": "2023-09-01T16:57:34.185047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "lr_d = 1\n",
    "acc_size = 8\n",
    "training_epochs1 = 100000 // len(train_loader)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr_d)\n",
    "\n",
    "model_test = torch.nn.DataParallel(model)\n",
    "model_test.to('cuda:0')\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optim, start_factor=1.0, end_factor=0.1, total_iters=training_epochs1*len(train_loader))\n",
    "scheduler = NoamLR(optim, 100000, 512)\n",
    "\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25684f3b-1b46-41f3-ab64-342dd82ffb6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:35.484558Z",
     "iopub.status.busy": "2023-09-01T16:57:35.484376Z",
     "iopub.status.idle": "2023-09-01T16:57:35.490204Z",
     "shell.execute_reply": "2023-09-01T16:57:35.489312Z",
     "shell.execute_reply.started": "2023-09-01T16:57:35.484542Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2292, 43, 98556)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), training_epochs1, training_epochs1 * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a8ee36c-93ab-408d-9171-951b2d01c63e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:35.491049Z",
     "iopub.status.busy": "2023-09-01T16:57:35.490889Z",
     "iopub.status.idle": "2023-09-01T16:57:35.526225Z",
     "shell.execute_reply": "2023-09-01T16:57:35.525314Z",
     "shell.execute_reply.started": "2023-09-01T16:57:35.491034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.cpu()(batch['anchor'][None], batch['mask'][None], batch['channels'][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d301d68b-775a-47a1-a1a9-ff2ff4d20b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T16:57:35.527033Z",
     "iopub.status.busy": "2023-09-01T16:57:35.526875Z",
     "iopub.status.idle": "2023-09-01T16:57:35.551327Z",
     "shell.execute_reply": "2023-09-01T16:57:35.550261Z",
     "shell.execute_reply.started": "2023-09-01T16:57:35.527019Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# for epoch in range(training_epochs1):\n",
    "#     mean_loss = 0\n",
    "#     acc_step = 0\n",
    "#     for batch in train_loader:\n",
    "#         logits = model_test(\n",
    "#             batch['anchor'],#.to('cuda:0'), \n",
    "#             None,\n",
    "#             batch['channels'].long(),\n",
    "#             clf=False)\n",
    "#         ae, label = model_test(\n",
    "#             batch['anchor'],#.to('cuda:0'), \n",
    "#             None, \n",
    "#             batch['channels'].long())\n",
    "        \n",
    "#         logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "#         fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "#         loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "#         loss = loss.mean()\n",
    "#         loss.backward()\n",
    "#         mean_loss += loss.item()\n",
    "#         acc_step += 1\n",
    "#         steps += 1\n",
    "#         # raise\n",
    "#         if acc_step != 0 and acc_step % acc_size == 0:\n",
    "#             optim.step()\n",
    "#             scheduler.step()\n",
    "#             optim.zero_grad()\n",
    "#             if steps % 100 == 0:\n",
    "#                 print('Loss/train\\t{}'.format(mean_loss / acc_size))\n",
    "#             writer.add_scalar('Loss/train', mean_loss / acc_size, steps)\n",
    "#             mean_loss = 0\n",
    "#         if steps != 0 and steps % 1000 == 0:\n",
    "#             der = 0\n",
    "#             try:\n",
    "#                 with torch.no_grad():\n",
    "#                     for batch in test_loader:\n",
    "#                         ae, label = model_test(\n",
    "#                             batch['anchor'],#.to('cuda:0'), \n",
    "#                             None, \n",
    "#                             batch['channels'].long())\n",
    "#                         logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "#                         fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "#                         loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "#                         loss = loss.mean() / acc_size\n",
    "#                         der += loss\n",
    "#                 der /= len(test_loader)\n",
    "#                 writer.add_scalar('Loss/test', der, steps)\n",
    "\n",
    "#                 print('Loss: {}\\t'.format(der))\n",
    "#             except:\n",
    "#                 raise\n",
    "#             # torch.save(model_test.module.state_dict(), 'models/step.pt'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b119cee-d759-4fd8-a8bf-130e8b8d17d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70c6f2da-c79a-42e4-999b-dbe380572ada",
   "metadata": {},
   "source": [
    "## INFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a92b3c3-9765-4401-bd81-7cb07d97c907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T11:53:11.691488Z",
     "iopub.status.busy": "2023-09-05T11:53:11.690753Z",
     "iopub.status.idle": "2023-09-05T11:53:11.699409Z",
     "shell.execute_reply": "2023-09-05T11:53:11.697801Z",
     "shell.execute_reply.started": "2023-09-05T11:53:11.691425Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path10 = Path('/media/hdd/pretraining/synt_data/data_10')\n",
    "path12 = Path('/media/hdd/pretraining/synt_data/data_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "94f35715-a2a8-4983-971b-4230e2453559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:08:40.634586Z",
     "iopub.status.busy": "2023-09-05T15:08:40.634297Z",
     "iopub.status.idle": "2023-09-05T15:08:40.734049Z",
     "shell.execute_reply": "2023-09-05T15:08:40.732587Z",
     "shell.execute_reply.started": "2023-09-05T15:08:40.634565Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _SelectChannels(sample, channels=channels):\n",
    "    signal = sample['value_pure']\n",
    "    \n",
    "    channels_ids = [i for i, val in enumerate(sample['channels']) if i != 3 and val in channels]\n",
    "    \n",
    "    \n",
    "    # choose 2 random channels\n",
    "    # channels_to_train = np.random.choice(channels_ids, 2, replace=False)\n",
    "    # use all available\n",
    "    channels_to_train = channels_ids\n",
    "    signal = signal[:, channels_to_train]\n",
    "    return signal, channels_to_train\n",
    "\n",
    "\n",
    "class SYNT(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, labels, preprocess_montage:Callable=_SelectChannels) :\n",
    "        super(SYNT, self).__init__()\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.preprocess_montage=preprocess_montage\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        # take 60s of recording with specified shift\n",
    "        sample = np.load(path, allow_pickle=True)\n",
    "        sample = {'value_pure':sample, 'channels':channels}\n",
    "        \n",
    "        # key = False\n",
    "        # while(key == False):\n",
    "        #     try:\n",
    "        #         key = True\n",
    "        #     except Exception as e:\n",
    "        #         print(\"Path: {} is broken \".format(path), e)\n",
    "        #         path = np.random.choice(self.paths, 1)[0]\n",
    "                \n",
    "\n",
    "        signal, channels_to_train = self.preprocess_montage(sample)\n",
    "        real_len = signal.shape[0]\n",
    "\n",
    "        channels_vector = torch.tensor((channels_to_train))\n",
    "\n",
    "        \n",
    "        # remove normalization for now with within channel z-norm\n",
    "        # sample_norm = (sample - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector]) / (tuh_filtered_stat_vals['max_vals_filtered'][channels_vector] - tuh_filtered_stat_vals['min_vals_filtered'][channels_vector] + 1e-6)\n",
    "        sample_norm_mean = signal.mean()\n",
    "        sample_norm_std = np.std(signal)\n",
    "        \n",
    "        signal_norm = (signal - sample_norm_mean) / (sample_norm_std)\n",
    "        \n",
    "        if signal_norm.shape[0] < 6000:\n",
    "            signal_norm = np.pad(signal_norm, ((0, 6000 - signal_norm.shape[0]), (0, 0)))\n",
    "        \n",
    "        attention_mask = torch.ones(6000)\n",
    "        attention_mask[real_len:] = 0\n",
    "        return {'anchor': torch.from_numpy(signal_norm).float(), \n",
    "                'label': self.labels[idx], \n",
    "                # 'anchor_masked': torch.from_numpy(sample_masked).float(), \n",
    "                # 'mask': torch.tensor(mask),\n",
    "                'channels': channels_vector,\n",
    "                'attention_mask': attention_mask}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# paths = list(path10.glob(\"*.npy\"))\n",
    "# synt_dataset = SYNT(paths, labels=[0 for a in paths])\n",
    "# synt_loader = torch.utils.data.DataLoader(synt_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "# paths = list(path10.glob(\"*.npy\"))\n",
    "# synt_dataset12 = SYNT(paths, labels=np.ones(len(paths)))\n",
    "# synt_loader12 = torch.utils.data.DataLoader(synt_dataset12, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "paths_train = list(path10.glob(\"*.npy\"))[:1000] + list(path12.glob(\"*.npy\"))[:1000]\n",
    "synt_dataset_train = SYNT(paths_train, labels=np.r_[np.ones(len(paths_train)), np.zeros(len(paths))])\n",
    "synt_loader_train = torch.utils.data.DataLoader(synt_dataset_train, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n",
    "\n",
    "paths_test = list(path10.glob(\"*.npy\"))[-1000:] + list(path12.glob(\"*.npy\"))[-1000:]\n",
    "synt_dataset_test = SYNT(paths_test, labels=np.r_[np.ones(len(paths_test)), np.zeros(len(paths))])\n",
    "synt_loader_test = torch.utils.data.DataLoader(synt_dataset_test, batch_size=64, shuffle=True, num_workers=0, drop_last=True, worker_init_fn = worker_init_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d75640a5-3ced-4460-af3d-1c4c188d7986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:08:45.951536Z",
     "iopub.status.busy": "2023-09-05T15:08:45.951241Z",
     "iopub.status.idle": "2023-09-05T15:08:46.004012Z",
     "shell.execute_reply": "2023-09-05T15:08:46.002250Z",
     "shell.execute_reply.started": "2023-09-05T15:08:45.951513Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(path12.glob(\"*.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d728f769-bff6-4ecf-b750-a3e183a65366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:07:13.506555Z",
     "iopub.status.busy": "2023-09-05T15:07:13.506222Z",
     "iopub.status.idle": "2023-09-05T15:07:17.435870Z",
     "shell.execute_reply": "2023-09-05T15:07:17.434801Z",
     "shell.execute_reply.started": "2023-09-05T15:07:13.506529Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(cc)\n\u001b[1;32m     40\u001b[0m sample\u001b[38;5;241m=\u001b[39mbatch\n\u001b[0;32m---> 41\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manchor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m       \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((output, output), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[162], line 18\u001b[0m, in \u001b[0;36mClassifierEEGEmbedder.forward\u001b[0;34m(self, inputs, attention_mask, ch_vector)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, attention_mask, ch_vector,):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# x, label= self.pretrained(inputs, attention_mask, ch_vector,)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     x, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained(inputs, attention_mask, ch_vector)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmy_new_layers(label)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "class ClassifierEEGEmbedder(torch.nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(ClassifierEEGEmbedder, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.masking = False\n",
    "        # self.my_new_layers = torch.nn.Sequential(torch.nn.Linear(self.pretrained.config.hidden_size, self.pretrained.config.num_labels),\n",
    "        #                                         torch.nn.Linear(self.pretrained.config.hidden_size, self.pretrained.config.num_labels))\n",
    "    \n",
    "    \n",
    "        self.my_new_layers = torch.nn.Sequential(\n",
    "            # torch.nn.Linear(768, 256),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.Linear(256, 2),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, inputs, attention_mask, ch_vector,):\n",
    "        # x, label= self.pretrained(inputs, attention_mask, ch_vector,)\n",
    "        x, label = self.pretrained(inputs, attention_mask, ch_vector)\n",
    "        \n",
    "        # print(x)\n",
    "        x = self.my_new_layers(label)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "\n",
    "    \n",
    "model2 = ClassifierEEGEmbedder(model).to(device)\n",
    "output = torch.tensor((0,0,2))\n",
    "for synt in [synt_loader, synt_loader12]:\n",
    "    cc = 0\n",
    "    \n",
    "    for batch in synt:\n",
    "        cc +=1\n",
    "        if cc > 1:\n",
    "            break\n",
    "        print(cc)\n",
    "\n",
    "        sample=batch\n",
    "        output = model2(sample['anchor'].to(device), \n",
    "               None, \n",
    "               sample['channels'].long().to(device)\n",
    "              )\n",
    "        output = torch.cat((output, output), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ef744e08-8cd7-4684-97ea-91a16772cb0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T11:28:41.034114Z",
     "iopub.status.busy": "2023-09-07T11:28:41.033353Z",
     "iopub.status.idle": "2023-09-07T11:28:41.466427Z",
     "shell.execute_reply": "2023-09-07T11:28:41.465561Z",
     "shell.execute_reply.started": "2023-09-07T11:28:41.034081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['classifier.0.weight', 'classifier.0.bias', 'classifier.1.weight', 'classifier.1.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EEGEmbedder()\n",
    "model.masking=False\n",
    "model.clf=True\n",
    "model.load_state_dict(torch.load('/media/hdd/pretraining/models/step.pt'), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b6570-ccb4-47b6-a379-3c4316fb7bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2a26390c-db2b-4c99-8be6-fdbeebad87e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T11:29:28.271381Z",
     "iopub.status.busy": "2023-09-07T11:29:28.271005Z",
     "iopub.status.idle": "2023-09-07T11:29:32.598030Z",
     "shell.execute_reply": "2023-09-07T11:29:32.596984Z",
     "shell.execute_reply.started": "2023-09-07T11:29:28.271349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(cc)\n\u001b[1;32m     17\u001b[0m sample\u001b[38;5;241m=\u001b[39mbatch\n\u001b[0;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manchor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m       \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((output, output), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[162], line 18\u001b[0m, in \u001b[0;36mClassifierEEGEmbedder.forward\u001b[0;34m(self, inputs, attention_mask, ch_vector)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, attention_mask, ch_vector,):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# x, label= self.pretrained(inputs, attention_mask, ch_vector,)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     x, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained(inputs, attention_mask, ch_vector)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmy_new_layers(label)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model = EEGEmbedder()\n",
    "model.masking=False\n",
    "model.clf=True\n",
    "model.load_state_dict(torch.load('/media/hdd/pretraining/models/step.pt'), strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "output = torch.tensor((0,0,2))\n",
    "for synt in [synt_loader, synt_loader12]:\n",
    "    cc = 0\n",
    "    \n",
    "    for batch in synt:\n",
    "        cc +=1\n",
    "        if cc > 1:\n",
    "            break\n",
    "        print(cc)\n",
    "\n",
    "        sample=batch\n",
    "        output = model2(sample['anchor'].to(device), \n",
    "               None, \n",
    "               sample['channels'].long().to(device)\n",
    "              )\n",
    "        output = torch.cat((output, output), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b765a26a-61c1-43c0-819d-abbfcd1989fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T11:30:06.875162Z",
     "iopub.status.busy": "2023-09-07T11:30:06.874773Z",
     "iopub.status.idle": "2023-09-07T11:30:10.754370Z",
     "shell.execute_reply": "2023-09-07T11:30:10.753317Z",
     "shell.execute_reply.started": "2023-09-07T11:30:06.875129Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manchor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[162], line 18\u001b[0m, in \u001b[0;36mClassifierEEGEmbedder.forward\u001b[0;34m(self, inputs, attention_mask, ch_vector)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, attention_mask, ch_vector,):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# x, label= self.pretrained(inputs, attention_mask, ch_vector,)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     x, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained(inputs, attention_mask, ch_vector)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmy_new_layers(label)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model2(sample['anchor'].to(device), \n",
    "               None, \n",
    "               sample['channels'].long().to(device)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625ec96-d6cf-4dfc-94b7-5013090bbc20",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-05T15:04:48.398611Z",
     "iopub.status.idle": "2023-09-05T15:04:48.398837Z",
     "shell.execute_reply": "2023-09-05T15:04:48.398738Z",
     "shell.execute_reply.started": "2023-09-05T15:04:48.398728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.median(output, axis=-2).values.detach().numpy())\n",
    "plt.axvline(output.shape[0]/2, linestyle='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909503f-02b7-42f5-80e5-ecf608c18d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(training_epochs1):\n",
    "    mean_loss = 0\n",
    "    acc_step = 0\n",
    "    for batch in train_loader:\n",
    "        logits = model_test(\n",
    "            batch['anchor'],#.to('cuda:0'), \n",
    "            None,\n",
    "            batch['channels'].long(),\n",
    "            clf=False)\n",
    "        ae, label = model_test(\n",
    "            batch['anchor'],#.to('cuda:0'), \n",
    "            None, \n",
    "            batch['channels'].long())\n",
    "        \n",
    "        logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "        fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        mean_loss += loss.item()\n",
    "        acc_step += 1\n",
    "        steps += 1\n",
    "        # raise\n",
    "        if acc_step != 0 and acc_step % acc_size == 0:\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad()\n",
    "            if steps % 100 == 0:\n",
    "                print('Loss/train\\t{}'.format(mean_loss / acc_size))\n",
    "            writer.add_scalar('Loss/train', mean_loss / acc_size, steps)\n",
    "            mean_loss = 0\n",
    "        if steps != 0 and steps % 1000 == 0:\n",
    "            der = 0\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_loader:\n",
    "                        ae, label = model_test(\n",
    "                            batch['anchor'],#.to('cuda:0'), \n",
    "                            None, \n",
    "                            batch['channels'].long())\n",
    "                        logits = _calculate_similarity(torch.transpose(label, 1, 2), torch.transpose(ae, 1, 2), _generate_negatives(torch.transpose(label, 1, 2))[0])\n",
    "\n",
    "                        fake_labels = torch.zeros(logits.shape[0], device=logits.device, dtype=torch.long)\n",
    "                        loss = torch.nn.CrossEntropyLoss()(logits, fake_labels) + 0.001 * label.pow(2).mean()\n",
    "\n",
    "                        loss = loss.mean() / acc_size\n",
    "                        der += loss\n",
    "                der /= len(test_loader)\n",
    "                writer.add_scalar('Loss/test', der, steps)\n",
    "\n",
    "                print('Loss: {}\\t'.format(der))\n",
    "            except:\n",
    "                raise\n",
    "            # torch.save(model_test.module.state_dict(), 'models/step.pt'.format(steps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
