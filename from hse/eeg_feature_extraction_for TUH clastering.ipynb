{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fac45f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:10:37.722910700Z",
     "start_time": "2023-10-06T12:10:35.624192300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# MNE modules\n",
    "import mne\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mne.set_log_level(verbose='CRITICAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300cfe3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:10:43.672337800Z",
     "start_time": "2023-10-06T12:10:43.607337800Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_bands():\n",
    "    # Frequency bands\n",
    "    bands = [(0.9, 4, 'Delta (0.9-4 Hz)', 'D'), (4, 8, 'Theta (4-8 Hz)', 'T'), (8, 14, 'Alpha (8-14 Hz)', 'A'),\n",
    "             (14, 25, 'Beta (14-25 Hz)', 'B'), (25, 40, 'Gamma (25-40 Hz)', 'G')]\n",
    "\n",
    "    str_freq = [bands[i][3] for i in range(len(bands))]\n",
    "\n",
    "    # Localization by scalp regions\n",
    "    regions = [(['Fp1', 'Fp2'], 'Fp', 'Pre-frontal'), (['F7', 'F3'], 'LF', 'Left Frontal'),\n",
    "               (['Fz'], 'MF', 'Midline Frontal'), (['F4', 'F8'], 'RF', 'Right Frontal'),\n",
    "               (['C3'], 'LT', 'Left Temporal'), (['P8'], 'RT', 'Right Temporal'),\n",
    "               (['C3', 'Cz', 'C4'], 'Cen', 'Central'), (['P3', 'Pz', 'P4'], 'Par', 'Parietal'),\n",
    "               (['O1', 'O2'], 'Occ', 'Occipital')]\n",
    "\n",
    "    SLICE_LEN = 10  # number of epochs to measure features, coherence and PLV\n",
    "\n",
    "    n_freq = len(str_freq)\n",
    "    n_regions = len(regions)\n",
    "\n",
    "    return bands, str_freq, regions, SLICE_LEN, n_freq, n_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bfee4b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:10:45.255020500Z",
     "start_time": "2023-10-06T12:10:45.191020900Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(sample, window=219, step=32, samp_rate=100):\n",
    "    sliced_data = []\n",
    "    slices_amount = int((sample.shape[0] - window) / step + 1)\n",
    "    for i in range(slices_amount):\n",
    "        slicee = sample[0 + i*step :window + i*step, :]\n",
    "        sliced_data.append(slicee)\n",
    "    sliced_data = np.array(sliced_data) # events, chanels, window\n",
    "    sliced_data = sliced_data.reshape(slices_amount, sample.shape[1], window)\n",
    "\n",
    "    ch_names = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4', 'O1', 'O2']\n",
    "    n_channels = len(ch_names)\n",
    "    bands, str_freq, regions, SLICE_LEN, n_freq, n_regions = define_bands()\n",
    "    \n",
    "    kwargs = dict(fmin=bands[0][0], fmax=bands[-1][1], sfreq=samp_rate, bandwidth=None, adaptive=True, n_jobs=1)\n",
    "    loc_masks = [[ch_names[i] in reg for i in range(n_channels)] for (reg, _, _) in regions]\n",
    "    \n",
    "    lst_st_psd_raw = []\n",
    "    lst_st_psd_loc_raw = []\n",
    "    lst_st_psd_all_raw = []\n",
    "    \n",
    "    st_psd_mtaper, st_freq_mtaper = psd_array_multitaper(sliced_data, **kwargs)\n",
    "    freq_masks = [(fmin < st_freq_mtaper) & (st_freq_mtaper < fmax) for (fmin, fmax, _, _) in bands]\n",
    "    \n",
    "    \n",
    "        # Stages\n",
    "    st_psd_raw = np.array([np.mean(st_psd_mtaper[:, :, _freq_mask], axis=2) for _freq_mask in freq_masks]).transpose(1,\n",
    "                                                                                                                     2,\n",
    "                                                                                                                     0)\n",
    "    st_psd_loc_raw = np.array([np.mean(st_psd_raw[:, _mask, :], axis=1) for _mask in loc_masks]).transpose(1, 0, 2)\n",
    "    st_psd_all_raw = np.mean(st_psd_raw, axis=1)\n",
    "\n",
    "    df_st_raw = pd.DataFrame()\n",
    "    df_st_loc_raw = pd.DataFrame()\n",
    "    df_st_all_raw = pd.DataFrame()\n",
    "    for _fr in range(n_freq):\n",
    "        for _ch in range(n_channels):\n",
    "            df_st_raw[str_freq[_fr] + '_psd_' + ch_names[_ch]] = st_psd_raw[:, _ch, _fr]\n",
    "        for _r in range(n_regions):\n",
    "            df_st_loc_raw[str_freq[_fr] + '_psd_' + regions[_r][1]] = st_psd_loc_raw[:, _r, _fr]\n",
    "        df_st_all_raw[str_freq[_fr] + '_psd_All'] = st_psd_all_raw[:, _fr]\n",
    "    \n",
    "    \n",
    "    df = df_st_raw\n",
    "\n",
    "    lst_st = 10 * np.log10(df[SLICE_LEN // 2:-SLICE_LEN // 2]) #- 10 * np.log10(df_blm_psd_raw.mean(axis=0))\n",
    "    # need to subtract baseline!!!\n",
    "    # so need to have baseline file\n",
    "    \n",
    "    return lst_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4634b777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:10:49.067304Z",
     "start_time": "2023-10-06T12:10:49.049301Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_indices(psd_previous):\n",
    "    samp_rate = 100\n",
    "    ch_names = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4', 'O1', 'O2']\n",
    "    n_channels = len(ch_names)\n",
    "    \n",
    "    bands, str_freq, regions, SLICE_LEN, n_freq, n_regions = define_bands()\n",
    "    print('Defining PSD indices...')\n",
    "\n",
    "    # PSD special features (EEG indices) (re-referenced data)\n",
    "\n",
    "    lst_st_psd_ind_raw = []\n",
    "    lst_st_psd_ind_loc_raw = []\n",
    "    lst_st_psd_ind_all_raw = []\n",
    "\n",
    "    str_psd_ind = ['T_D', 'A_D', 'A_T', 'A_DT', 'B_D', 'B_T', 'B_A', 'B_DT', 'B_TA', 'G_D', 'G_T', 'G_A', 'G_B', 'G_DT',\n",
    "                   'G_TA', 'G_AB']\n",
    "\n",
    "    df_st_raw = pd.DataFrame()\n",
    "    df_st_loc_raw = pd.DataFrame()\n",
    "    df_st_all_raw = pd.DataFrame()\n",
    "\n",
    "    # Indices per channel (averaged PSD)\n",
    "    for _ch in range(n_channels):\n",
    "        for ind in str_psd_ind:\n",
    "            if (len(ind) == 3):\n",
    "                df_st_raw[ind + '_psd_' + ch_names[_ch]] = (psd_previous[ind[0] + '_psd_' + ch_names[_ch]] /\n",
    "                                                            psd_previous[ind[2] + '_psd_' + ch_names[_ch]])\n",
    "            elif (len(ind) == 4):\n",
    "                df_st_raw[ind + '_psd_' + ch_names[_ch]] = (psd_previous[ind[0] + '_psd_' + ch_names[_ch]] /\n",
    "                                                            psd_previous[ind[2] + '_psd_' + ch_names[_ch]] +\n",
    "                                                             psd_previous[ind[3] + '_psd_' + ch_names[_ch]])\n",
    "    lst_st_psd_ind_raw = df_st_raw\n",
    "    lst_st_psd_ind_loc_raw = df_st_loc_raw\n",
    "    lst_st_psd_ind_all_raw = df_st_all_raw\n",
    "\n",
    "    # Aggregate all stages in one DataFrame\n",
    "    df = lst_st_psd_ind_raw\n",
    "    lst_st = 10 * np.log10(df[SLICE_LEN // 2:-SLICE_LEN // 2]) #- 10 * np.log10(df_blm_psd_ind_raw.mean(axis=0)\n",
    "\n",
    "    return lst_st # == df_st_psd_ind_db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efab1343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:10:56.267589200Z",
     "start_time": "2023-10-06T12:10:56.230590Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------Data-----------------------------------------------------\n",
    "class TEST_TUH(torch.utils.data.Dataset):\n",
    "    def __init__(self, path): #, tuh_filtered_stat_vals):\n",
    "        super(TEST_TUH, self).__init__()\n",
    "        self.main_path = path\n",
    "        self.paths = path\n",
    "        print(self.paths)\n",
    "        # self.tuh_filtered_stat_vals = tuh_filtered_stat_vals\n",
    "        # self.paths = ['{}/{}'.format(self.main_path, i) for i in os.listdir(self.main_path)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx, negative=False):\n",
    "        path = self.paths[idx]\n",
    "        # take 60s of recording with specified shift\n",
    "        key = False\n",
    "        while (key == False):\n",
    "            try:\n",
    "                # sample = np.load(path, allow_pickle=True).item()['value']\n",
    "                sample = np.load(path, allow_pickle=True).item()\n",
    "                key = True\n",
    "            except Exception as e:\n",
    "                print(\"Path: {} is broken \".format(path), e)\n",
    "                path = np.random.choice(self.paths, 1)[0]\n",
    "                # sample = np.load(path, allow_pickle=True).item()['value']\n",
    "        real_len = min(3000, sample['value_pure'].shape[0])\n",
    "\n",
    "        HSE_Stage2_channels = ['Fp1', 'FP2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4', 'O1', 'O2']\n",
    "        HSE_Stage2_channels = [i.upper() for i in HSE_Stage2_channels]\n",
    "        channels_ids = [i for i, val in enumerate(sample['channels']) if val in HSE_Stage2_channels]\n",
    "\n",
    "        sample = sample['value_pure'][:real_len]\n",
    "\n",
    "        # choose 2 random channels\n",
    "        channels_to_train = channels_ids  # np.random.choice(channels_ids, 2, replace=False)\n",
    "        channels_vector = torch.tensor((channels_to_train))\n",
    "        sample = sample[:, channels_to_train]\n",
    "\n",
    "        sample_norm = sample\n",
    "        if sample_norm.shape[0] < 3000:\n",
    "            sample_norm = np.pad(sample_norm, ((0, 3000 - sample_norm.shape[0]), (0, 0)))\n",
    "        print(sample_norm.shape)\n",
    "        lst_st_feat = extract_features(sample_norm)\n",
    "        indices = features_indices(lst_st_feat)\n",
    "        df_st_eeg = pd.concat([lst_st_feat, indices], axis=1).dropna()\n",
    "\n",
    "        if np.random.choice([0, 1], p=[0.7, 0.3]) and not negative:\n",
    "            index = np.random.choice(self.__len__() - 1)\n",
    "            negative_sample = self.__getitem__(index, True)\n",
    "            negative_path = negative_sample['path']\n",
    "            negative_sample_norm = negative_sample['current'].numpy()\n",
    "\n",
    "            negative_person = negative_sample['path'].split('/')[-1]  # .split('_')\n",
    "            current_person = path.split('/')[-1]  # .split('_')\n",
    "            if negative_person.split('_')[0] == current_person.split('_')[0] and \\\n",
    "                    abs(int(negative_person.split('_')[1][:-4]) - int(current_person.split('_')[1][:-4])) < 20000:\n",
    "                negative_label = torch.tensor(0)               # возможно стоит запретить позитивы отличающиеся < 20000 , если состояние реально изменилось то сеть будет учиться странному.\n",
    "            else:\n",
    "                negative_label = torch.tensor(1)\n",
    "        else:\n",
    "            negative_sample_norm = sample_norm.copy()\n",
    "            negative_label = torch.tensor(0)\n",
    "            negative_path = ''\n",
    "\n",
    "        attention_mask = torch.ones(3000)\n",
    "        attention_mask[real_len:] = 0\n",
    "        return {'current': torch.from_numpy(sample_norm).float(),\n",
    "                'negative': torch.from_numpy(negative_sample_norm).float(),\n",
    "                'path': path,\n",
    "                'label': negative_label,\n",
    "                'channels': channels_vector,\n",
    "                'attention_mask': attention_mask,\n",
    "               'features': df_st_eeg.to_numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196fd73f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:10:58.354796500Z",
     "start_time": "2023-10-06T12:10:58.331792600Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/example_data/TUH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf9b155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:11:00.360094900Z",
     "start_time": "2023-10-06T12:11:00.351094900Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitted_paths = [f'{path}/{i}'.format(i) for i in os.listdir(path)]\n",
    "splitted_paths = ['/media/hdd/data/TUH_splited.examples/{}'.format(i) for i in os.listdir('/media/hdd/data/TUH_splited.examples/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922af638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:11:55.553713500Z",
     "start_time": "2023-10-06T12:11:55.531710600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/hdd/data/TUH_splited.examples/2_0.npy', '/media/hdd/data/TUH_splited.examples/0_0.npy']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TEST_TUH(splitted_paths[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7262e39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T07:15:51.456445800Z",
     "start_time": "2023-10-06T07:15:51.449446100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c40475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:08:15.533033900Z",
     "start_time": "2023-10-06T12:08:15.246064800Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtrain_loader\u001B[49m:\n\u001B[1;32m      2\u001B[0m     features \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    features = batch['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896871f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
